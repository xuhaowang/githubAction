[{"title":"CommitID[44f70f71492ba7]2019-10-23T20:22:23","tag":["app-pod-failure","pod-delete"],"time":"2019-10-23 20:22:23","url":"/post/2019-10-23T20:22:23","thumb":"/contents/2019-10-23T20:22:23/thumb.jpg","content":"=== \n标题： CommitID[44f70f71492ba7]2019-10-23T20:22:23\n标签： app-pod-failure, pod-delete\n\n=== \n\n\n# Summary report \n| Task status | number |\n| ------------ | ------------ |\n|      ok |      29\n|      change |      19\n|      unreachable |      0\n|      failed |      0\n# Info report \n ``` \namber: load the executor...\nci-enhanced: Pulling from diamond/service-providers/ansible-runner\nDigest: sha256:9b0d9b5684fd4d47abd9d45c016fd5ff835b1f810583b3e67886ca7c9bc0b877\nStatus: Image is up to date for registry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\nregistry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\namber: found the case.\namber: the executor is running...\nansible-playbook 2.7.3\n  config file = None\n  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/local/lib/python2.7/dist-packages/ansible\n  executable location = /usr/local/bin/ansible-playbook\n  python version = 2.7.15+ (default, Nov 27 2018, 23:36:35) [GCC 7.3.0]\nNo config file found; using defaults\n/etc/ansible/hosts did not meet host_list requirements, check plugin documentation if this is unexpected\n/etc/ansible/hosts did not meet script requirements, check plugin documentation if this is unexpected\nPLAYBOOK: test.yml \n plays in ./experiments/chaos/app-pod-failure/test.yml\nPLAY [localhost] \ntime:2019-10-22T09:32:35.674168 (delta: 0.040952)         elapsed: 0.040952  \n``` \n\n## TASK [Gathering Facts] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:2\ntime:2019-10-22T09:32:35.683676 (delta: 0.009465)         elapsed: 0.05046  \nok: [127.0.0.1]\nMETA: ran handlers\n``` \n\n## TASK [Setup] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:22\ntime:2019-10-22T09:32:41.686005 (delta: 6.002295)         elapsed: 6.052789  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Checking status of liveness pod] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:29\ntime:2019-10-22T09:32:41.724829 (delta: 0.038804)         elapsed: 6.091613  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record test instance/run ID] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:42\ntime:2019-10-22T09:32:41.761581 (delta: 0.036722)         elapsed: 6.128365  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Construct testname appended with runID] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:46\ntime:2019-10-22T09:32:41.798056 (delta: 0.036451)         elapsed: 6.16484  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Generate the litmus result CR to reflect SOT (Start of Test)] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:52\ntime:2019-10-22T09:32:41.837476 (delta: 0.039398)         elapsed: 6.20426  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"65f1f8950b2a825fd3c27f66a8ec4113524d53c0\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"5324f15d0d02e6175cce9e8a64219dfe\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 416, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736761.86-229086193671283/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:63\ntime:2019-10-22T09:32:42.227249 (delta: 0.389733)         elapsed: 6.594033  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:01.339873\", \"end\": \"2019-10-22 09:32:43.753129\", \"failed_when_result\": false, \"rc\": 0, \"start\": \"2019-10-22 09:32:42.413256\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"litmusresult.litmus.io/app-pod-failure created\", \"stdout_lines\": [\"litmusresult.litmus.io/app-pod-failure created\"]}\n``` \n\n## TASK [Display the app information passed via the test job] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:72\ntime:2019-10-22T09:32:43.800883 (delta: 1.573613)         elapsed: 8.167667  \nok: [127.0.0.1] => {\n    \"msg\": [\n        \"The application info is as follows:\", \n        \"Namespace    : default\", \n        \"Label        : statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0\"\n    ]\n}\n``` \n\n## TASK [Verify that the AUT is running] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:80\ntime:2019-10-22T09:32:43.864344 (delta: 0.063425)         elapsed: 8.231128  \nincluded: /utils/k8s/check_deployment_status.yml for 127.0.0.1\n``` \n\n## TASK [Check the pod status] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:8\ntime:2019-10-22T09:32:43.929680 (delta: 0.065294)         elapsed: 8.296464  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [obtain the number of replicas.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:22\ntime:2019-10-22T09:32:43.968507 (delta: 0.038789)         elapsed: 8.335291  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:spec.replicas\", \"delta\": \"0:00:00.446878\", \"end\": \"2019-10-22 09:32:44.528493\", \"rc\": 0, \"start\": \"2019-10-22 09:32:44.081615\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Obtain the ready replica count and compare with the replica count.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:29\ntime:2019-10-22T09:32:44.566536 (delta: 0.598006)         elapsed: 8.93332  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:..readyReplicas\", \"delta\": \"0:00:00.456628\", \"end\": \"2019-10-22 09:32:45.138732\", \"rc\": 0, \"start\": \"2019-10-22 09:32:44.682104\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Get application pod name] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:84\ntime:2019-10-22T09:32:45.177247 (delta: 0.61069)         elapsed: 9.544031  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [include_tasks] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:94\ntime:2019-10-22T09:32:45.218924 (delta: 0.041646)         elapsed: 9.585708  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Get application pod name] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:105\ntime:2019-10-22T09:32:45.256949 (delta: 0.037995)         elapsed: 9.623733  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o jsonpath='{.items[0].metadata.name}'\", \"delta\": \"0:00:00.465754\", \"end\": \"2019-10-22 09:32:45.826833\", \"rc\": 0, \"start\": \"2019-10-22 09:32:45.361079\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"cass-demo-dc1-rack1-0\", \"stdout_lines\": [\"cass-demo-dc1-rack1-0\"]}\n``` \n\n## TASK [include_tasks] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:114\ntime:2019-10-22T09:32:45.861121 (delta: 0.604145)         elapsed: 10.227905  \nincluded: /chaoslib/pumba/pod_failure_by_sigkill.yaml for 127.0.0.1\n``` \n\n## TASK [Setup pumba chaos infrastructure] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:4\ntime:2019-10-22T09:32:45.973179 (delta: 0.112037)         elapsed: 10.339963  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl apply -f /chaoslib/pumba/pumba_kube.yaml -n default\", \"delta\": \"0:00:00.570165\", \"end\": \"2019-10-22 09:32:46.653936\", \"rc\": 0, \"start\": \"2019-10-22 09:32:46.083771\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"daemonset.extensions/pumba created\", \"stdout_lines\": [\"daemonset.extensions/pumba created\"]}\n``` \n\n## TASK [Confirm that the pumba ds is running on all nodes] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:13\ntime:2019-10-22T09:32:46.695020 (delta: 0.721818)         elapsed: 11.061804  \nFAILED - RETRYING: Confirm that the pumba ds is running on all nodes (60 retries left).\nFAILED - RETRYING: Confirm that the pumba ds is running on all nodes (59 retries left).\nchanged: [127.0.0.1] => {\"attempts\": 3, \"changed\": true, \"cmd\": \"kubectl get pod -l app=pumba --no-headers -o custom-columns=:status.phase -n default | sort | uniq\", \"delta\": \"0:00:00.442172\", \"end\": \"2019-10-22 09:32:50.461738\", \"rc\": 0, \"start\": \"2019-10-22 09:32:50.019566\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"Running\", \"stdout_lines\": [\"Running\"]}\n``` \n\n## TASK [Select the app pod] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:27\ntime:2019-10-22T09:32:50.496854 (delta: 3.801803)         elapsed: 14.863638  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:36\ntime:2019-10-22T09:32:50.538436 (delta: 0.041559)         elapsed: 14.90522  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:43\ntime:2019-10-22T09:32:50.579263 (delta: 0.040803)         elapsed: 14.946047  \nok: [127.0.0.1] => {\"ansible_facts\": {\"app_pod_ut\": \"cass-demo-dc1-rack1-0\"}, \"changed\": false}\n``` \n\n## TASK [Identify the application node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:49\ntime:2019-10-22T09:32:50.638684 (delta: 0.059401)         elapsed: 15.005468  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod cass-demo-dc1-rack1-0 -n default --no-headers -o custom-columns=:spec.nodeName\", \"delta\": \"0:00:00.437792\", \"end\": \"2019-10-22 09:32:51.176349\", \"rc\": 0, \"start\": \"2019-10-22 09:32:50.738557\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"minikube\", \"stdout_lines\": [\"minikube\"]}\n``` \n\n## TASK [Record the application node name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:57\ntime:2019-10-22T09:32:51.209999 (delta: 0.571294)         elapsed: 15.576783  \nok: [127.0.0.1] => {\"ansible_facts\": {\"app_node\": \"minikube\"}, \"changed\": false}\n``` \n\n## TASK [Record the application container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:63\ntime:2019-10-22T09:32:51.270142 (delta: 0.060122)         elapsed: 15.636926  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pods -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -n default -o jsonpath='{.items[0].spec.containers[0].name}'\", \"delta\": \"0:00:00.439683\", \"end\": \"2019-10-22 09:32:51.814367\", \"rc\": 0, \"start\": \"2019-10-22 09:32:51.374684\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"cassandra\", \"stdout_lines\": [\"cassandra\"]}\n``` \n\n## TASK [Record the app_container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:70\ntime:2019-10-22T09:32:51.847909 (delta: 0.577746)         elapsed: 16.214693  \nok: [127.0.0.1] => {\"ansible_facts\": {\"app_container\": \"cassandra\"}, \"changed\": false}\n``` \n\n## TASK [Record the pumba pod on app node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:76\ntime:2019-10-22T09:32:51.907859 (delta: 0.059927)         elapsed: 16.274643  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod -l app=pumba -o wide -n default | grep minikube | awk '{print $1}'\", \"delta\": \"0:00:00.457465\", \"end\": \"2019-10-22 09:32:52.463953\", \"rc\": 0, \"start\": \"2019-10-22 09:32:52.006488\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"pumba-m9fhv\", \"stdout_lines\": [\"pumba-m9fhv\"]}\n``` \n\n## TASK [Record restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:85\ntime:2019-10-22T09:32:52.497435 (delta: 0.589554)         elapsed: 16.864219  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod cass-demo-dc1-rack1-0 -n default -o=jsonpath='{.status.containerStatuses[?(@.name==\\\"cassandra\\\")].restartCount}'\", \"delta\": \"0:00:00.445335\", \"end\": \"2019-10-22 09:32:53.043548\", \"rc\": 0, \"start\": \"2019-10-22 09:32:52.598213\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"5\", \"stdout_lines\": [\"5\"]}\n``` \n\n## TASK [Force kill the application pod using pumba] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:93\ntime:2019-10-22T09:32:53.077400 (delta: 0.579931)         elapsed: 17.444184  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl exec pumba-m9fhv -n default -- pumba kill --signal SIGKILL re2:k8s_cassandra_;\", \"delta\": \"0:00:02.174077\", \"end\": \"2019-10-22 09:32:55.351290\", \"rc\": 0, \"start\": \"2019-10-22 09:32:53.177213\", \"stderr\": \"time=\\\"2019-10-22T09:32:53Z\\\" level=info msg=\\\"Kill containers\\\" \\ntime=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-1_default_af292200-2d06-4f19-9970-e64d00ed8302_5 (adf6e7b0f6a8c4e23be92ac5f291e8809bd47205716f55252db121313be4dd00) with signal SIGKILL\\\" \\ntime=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-0_default_3fcd5226-3229-4deb-9930-279e6eec50cc_5 (f84f21e935ce22b26c8c4053354726b34e515e94f64b27e3e0564c929e1472f4) with signal SIGKILL\\\" \", \"stderr_lines\": [\"time=\\\"2019-10-22T09:32:53Z\\\" level=info msg=\\\"Kill containers\\\" \", \"time=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-1_default_af292200-2d06-4f19-9970-e64d00ed8302_5 (adf6e7b0f6a8c4e23be92ac5f291e8809bd47205716f55252db121313be4dd00) with signal SIGKILL\\\" \", \"time=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-0_default_3fcd5226-3229-4deb-9930-279e6eec50cc_5 (f84f21e935ce22b26c8c4053354726b34e515e94f64b27e3e0564c929e1472f4) with signal SIGKILL\\\" \"], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Verify restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:102\ntime:2019-10-22T09:32:55.389173 (delta: 2.311746)         elapsed: 19.755957  \nFAILED - RETRYING: Verify restartCount (30 retries left).\nchanged: [127.0.0.1] => {\"attempts\": 2, \"changed\": true, \"cmd\": \"kubectl get pod cass-demo-dc1-rack1-0 -n default -o=jsonpath='{.status.containerStatuses[?(@.name==\\\"cassandra\\\")].restartCount}'\", \"delta\": \"0:00:00.471000\", \"end\": \"2019-10-22 09:32:58.525225\", \"rc\": 0, \"start\": \"2019-10-22 09:32:58.054225\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"6\", \"stdout_lines\": [\"6\"]}\n``` \n\n## TASK [Check if pumba is indeed running] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:117\ntime:2019-10-22T09:32:58.565366 (delta: 3.176158)         elapsed: 22.93215  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Delete the pumba daemonset] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:132\ntime:2019-10-22T09:32:58.617708 (delta: 0.052315)         elapsed: 22.984492  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Confirm that the pumba ds is deleted successfully] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:139\ntime:2019-10-22T09:32:58.658968 (delta: 0.041197)         elapsed: 23.025752  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Checkpoint] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:127\ntime:2019-10-22T09:32:58.702607 (delta: 0.043593)         elapsed: 23.069391  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Verify AUT liveness post fault-injection] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:134\ntime:2019-10-22T09:32:58.746531 (delta: 0.043879)         elapsed: 23.113315  \nincluded: /utils/k8s/check_deployment_status.yml for 127.0.0.1\n``` \n\n## TASK [Check the pod status] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:8\ntime:2019-10-22T09:32:58.808217 (delta: 0.061654)         elapsed: 23.175001  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [obtain the number of replicas.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:22\ntime:2019-10-22T09:32:58.850771 (delta: 0.042514)         elapsed: 23.217555  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:spec.replicas\", \"delta\": \"0:00:00.487258\", \"end\": \"2019-10-22 09:32:59.454084\", \"rc\": 0, \"start\": \"2019-10-22 09:32:58.966826\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Obtain the ready replica count and compare with the replica count.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:29\ntime:2019-10-22T09:32:59.502144 (delta: 0.651351)         elapsed: 23.868928  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:..readyReplicas\", \"delta\": \"0:00:00.460006\", \"end\": \"2019-10-22 09:33:00.079589\", \"rc\": 0, \"start\": \"2019-10-22 09:32:59.619583\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Checking status of liveness pod] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:139\ntime:2019-10-22T09:33:00.131823 (delta: 0.629637)         elapsed: 24.498607  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [set_fact] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:148\ntime:2019-10-22T09:33:00.169972 (delta: 0.038111)         elapsed: 24.536756  \nok: [127.0.0.1] => {\"ansible_facts\": {\"flag\": \"Pass\"}, \"changed\": false}\n``` \n\n## TASK [Generate the litmus result CR to reflect EOT (End of Test)] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:159\ntime:2019-10-22T09:33:00.230381 (delta: 0.060385)         elapsed: 24.597165  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"0ce715eedb8ca906ea535c15dc4cf27e5c351360\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"e9d551b88b01b393b3e36a1afeb12822\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 414, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736780.27-79185624627260/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:170\ntime:2019-10-22T09:33:01.259316 (delta: 1.028891)         elapsed: 25.6261  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:00.680528\", \"end\": \"2019-10-22 09:33:02.041191\", \"failed_when_result\": false, \"rc\": 0, \"start\": \"2019-10-22 09:33:01.360663\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"litmusresult.litmus.io/app-pod-failure configured\", \"stdout_lines\": [\"litmusresult.litmus.io/app-pod-failure configured\"]}\n``` \n\n## TASK [include_tasks] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:177\ntime:2019-10-22T09:33:02.082162 (delta: 0.822823)         elapsed: 26.448946  \nincluded: /chaoslib/pumba/pod_failure_by_sigkill.yaml for 127.0.0.1\n``` \n\n## TASK [Setup pumba chaos infrastructure] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:4\ntime:2019-10-22T09:33:02.167201 (delta: 0.084983)         elapsed: 26.533985  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Confirm that the pumba ds is running on all nodes] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:13\ntime:2019-10-22T09:33:02.210265 (delta: 0.043041)         elapsed: 26.577049  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Select the app pod] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:27\ntime:2019-10-22T09:33:02.246121 (delta: 0.035817)         elapsed: 26.612905  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:36\ntime:2019-10-22T09:33:02.279515 (delta: 0.033368)         elapsed: 26.646299  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:43\ntime:2019-10-22T09:33:02.313912 (delta: 0.034359)         elapsed: 26.680696  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Identify the application node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:49\ntime:2019-10-22T09:33:02.348276 (delta: 0.034334)         elapsed: 26.71506  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the application node name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:57\ntime:2019-10-22T09:33:02.382690 (delta: 0.034383)         elapsed: 26.749474  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the application container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:63\ntime:2019-10-22T09:33:02.423818 (delta: 0.041072)         elapsed: 26.790602  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the app_container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:70\ntime:2019-10-22T09:33:02.460732 (delta: 0.036856)         elapsed: 26.827516  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the pumba pod on app node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:76\ntime:2019-10-22T09:33:02.524203 (delta: 0.06345)         elapsed: 26.890987  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:85\ntime:2019-10-22T09:33:02.581366 (delta: 0.057111)         elapsed: 26.94815  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Force kill the application pod using pumba] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:93\ntime:2019-10-22T09:33:02.624084 (delta: 0.042667)         elapsed: 26.990868  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Verify restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:102\ntime:2019-10-22T09:33:02.656630 (delta: 0.032513)         elapsed: 27.023414  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Check if pumba is indeed running] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:117\ntime:2019-10-22T09:33:02.694621 (delta: 0.037969)         elapsed: 27.061405  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get pod -l app=pumba --no-headers -o custom-columns=:status.phase -n default | sort | uniq\", \"delta\": \"0:00:00.474286\", \"end\": \"2019-10-22 09:33:03.279996\", \"rc\": 0, \"start\": \"2019-10-22 09:33:02.805710\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"Running\", \"stdout_lines\": [\"Running\"]}\n``` \n\n## TASK [Delete the pumba daemonset] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:132\ntime:2019-10-22T09:33:03.322117 (delta: 0.627443)         elapsed: 27.688901  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl delete -f /chaoslib/pumba/pumba_kube.yaml -n default\", \"delta\": \"0:00:00.497277\", \"end\": \"2019-10-22 09:33:03.942872\", \"rc\": 0, \"start\": \"2019-10-22 09:33:03.445595\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"daemonset.extensions \\\"pumba\\\" deleted\", \"stdout_lines\": [\"daemonset.extensions \\\"pumba\\\" deleted\"]}\n``` \n\n## TASK [Confirm that the pumba ds is deleted successfully] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:139\ntime:2019-10-22T09:33:03.978190 (delta: 0.656028)         elapsed: 28.344974  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Cleanup] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:186\ntime:2019-10-22T09:33:04.018832 (delta: 0.040603)         elapsed: 28.385616  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\nMETA: ran handlers\nMETA: ran handlers\nPLAY RECAP \n7.0.0.1\u001b[0m                  : \u001b[0;32mok=29  \u001b[0m \u001b[0;33mchanged=19  \u001b[0m unreachable=0    failed=0   \ntime:2019-10-22T09:33:04.045610 (delta: 0.026746)         elapsed: 28.412394  \namber: case app-pod-failure is going to finish...\namber: result would be available in CRD 'litmusresult' form. Use 'kubectl get lr' for details.\n``` \n"},{"title":"CommitID[11f70fs6s6ss]2019-10-23T20:22:38","tag":["network-delay"],"time":"2019-10-23 20:22:38","url":"/post/2019-10-23T20:22:38","thumb":"/contents/2019-10-23T20:22:38/thumb.jpg","content":"\n# Summary report \n| Task status | number |\n| ------------ | ------------ |\n|      ok |      4\n|      change |      2\n|      unreachable |      0\n|      failed |      2\n# Info report \n ``` \namber: load the executor...\nci-enhanced: Pulling from diamond/service-providers/ansible-runner\nDigest: sha256:9b0d9b5684fd4d47abd9d45c016fd5ff835b1f810583b3e67886ca7c9bc0b877\nStatus: Image is up to date for registry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\nregistry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\namber: found the case.\namber: the executor is running...\nansible-playbook 2.7.3\n  config file = None\n  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/local/lib/python2.7/dist-packages/ansible\n  executable location = /usr/local/bin/ansible-playbook\n  python version = 2.7.15+ (default, Nov 27 2018, 23:36:35) [GCC 7.3.0]\nNo config file found; using defaults\n/etc/ansible/hosts did not meet host_list requirements, check plugin documentation if this is unexpected\n/etc/ansible/hosts did not meet script requirements, check plugin documentation if this is unexpected\nPLAYBOOK: test.yml \n plays in ./experiments/chaos/test-kil-pod/test.yml\nPLAY [localhost] \ntime:2019-10-22T09:29:57.520349 (delta: 0.025844)         elapsed: 0.025844  \n``` \n\n## TASK [Gathering Facts] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:2\ntime:2019-10-22T09:29:57.525821 (delta: 0.005457)         elapsed: 0.031316  \nok: [127.0.0.1]\nMETA: ran handlers\n``` \n\n## TASK [Setup] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:22\ntime:2019-10-22T09:30:01.478122 (delta: 3.952288)         elapsed: 3.983617  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Checking status of liveness pod] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:29\ntime:2019-10-22T09:30:01.504660 (delta: 0.026522)         elapsed: 4.010155  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record test instance/run ID] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:42\ntime:2019-10-22T09:30:01.529959 (delta: 0.025251)         elapsed: 4.035454  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Construct testname appended with runID] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:46\ntime:2019-10-22T09:30:01.554921 (delta: 0.024944)         elapsed: 4.060416  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Generate the litmus result CR to reflect SOT (Start of Test)] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:52\ntime:2019-10-22T09:30:01.579924 (delta: 0.024985)         elapsed: 4.085419  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"f81d110b68adb61b8825de7c3d7f4b3df1b501f8\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"c65861c9362d3c8439358c316152274c\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 413, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736601.6-15922123312454/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:63\ntime:2019-10-22T09:30:02.318670 (delta: 0.738727)         elapsed: 4.824165  \nfatal: [127.0.0.1]: FAILED! => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:00.386998\", \"end\": \"2019-10-22 09:30:02.841993\", \"failed_when_result\": true, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2019-10-22 09:30:02.454995\", \"stderr\": \"Error in configuration: \\n unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\\n unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\\n unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\", \"stderr_lines\": [\"Error in configuration: \", \" unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\", \" unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\", \" unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\"], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [set_fact] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:152\ntime:2019-10-22T09:30:02.869357 (delta: 0.550668)         elapsed: 5.374852  \nok: [127.0.0.1] => {\"ansible_facts\": {\"flag\": \"Fail\"}, \"changed\": false}\n``` \n\n## TASK [Generate the litmus result CR to reflect EOT (End of Test)] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:159\ntime:2019-10-22T09:30:02.902128 (delta: 0.032751)         elapsed: 5.407623  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"032fbf1a09bbe4384dc7ccf52080d9aeca806323\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"e125d36fb6e935332e127564201fb1e1\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 411, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736602.92-122613202543123/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:170\ntime:2019-10-22T09:30:03.500344 (delta: 0.598197)         elapsed: 6.005839  \nfatal: [127.0.0.1]: FAILED! => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:00.261548\", \"end\": \"2019-10-22 09:30:03.832748\", \"failed_when_result\": true, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2019-10-22 09:30:03.571200\", \"stderr\": \"Error in configuration: \\n unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\\n unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\\n unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\", \"stderr_lines\": [\"Error in configuration: \", \" unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\", \" unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\", \" unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\"], \"stdout\": \"\", \"stdout_lines\": []}\nPLAY RECAP \n7.0.0.1                  : \u001b[0;32mok=4    \u001b[0;33mchanged=2    unreachable=0    \u001b[0;31mfailed=2   \ntime:2019-10-22T09:30:03.847634 (delta: 0.347272)         elapsed: 6.353129  \namber: case test-kil-pod is going to finish...\namber: result would be available in CRD 'litmusresult' form. Use 'kubectl get lr' for details.\n``` \n"},{"title":"CommitID[73570f71492ba7]2019-10-23T21:22:38 ","tag":["network-delay","pod-delete"],"time":"2019-10-23 21:22:38 ","url":"/post/2019-10-23T21:22:38 ","thumb":"/contents/2019-10-23T21:22:38 /thumb.jpg","content":"=== \n标题： CommitID[73570f71492ba7]2019-10-23T21:22:38 \n标签： network-delay, pod-delete\n\n=== \n\n\n# Summary report \n| Task status | number |\n| ------------ | ------------ |\n|      ok |      4\n|      change |      2\n|      unreachable |      0\n|      failed |      2\n# Info report \n ``` \namber: load the executor...\nci-enhanced: Pulling from diamond/service-providers/ansible-runner\nDigest: sha256:9b0d9b5684fd4d47abd9d45c016fd5ff835b1f810583b3e67886ca7c9bc0b877\nStatus: Image is up to date for registry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\nregistry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\namber: found the case.\namber: the executor is running...\nansible-playbook 2.7.3\n  config file = None\n  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/local/lib/python2.7/dist-packages/ansible\n  executable location = /usr/local/bin/ansible-playbook\n  python version = 2.7.15+ (default, Nov 27 2018, 23:36:35) [GCC 7.3.0]\nNo config file found; using defaults\n/etc/ansible/hosts did not meet host_list requirements, check plugin documentation if this is unexpected\n/etc/ansible/hosts did not meet script requirements, check plugin documentation if this is unexpected\nPLAYBOOK: test.yml \n plays in ./experiments/chaos/test-kil-pod/test.yml\nPLAY [localhost] \ntime:2019-10-22T09:29:57.520349 (delta: 0.025844)         elapsed: 0.025844  \n``` \n\n## TASK [Gathering Facts] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:2\ntime:2019-10-22T09:29:57.525821 (delta: 0.005457)         elapsed: 0.031316  \nok: [127.0.0.1]\nMETA: ran handlers\n``` \n\n## TASK [Setup] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:22\ntime:2019-10-22T09:30:01.478122 (delta: 3.952288)         elapsed: 3.983617  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Checking status of liveness pod] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:29\ntime:2019-10-22T09:30:01.504660 (delta: 0.026522)         elapsed: 4.010155  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record test instance/run ID] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:42\ntime:2019-10-22T09:30:01.529959 (delta: 0.025251)         elapsed: 4.035454  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Construct testname appended with runID] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:46\ntime:2019-10-22T09:30:01.554921 (delta: 0.024944)         elapsed: 4.060416  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Generate the litmus result CR to reflect SOT (Start of Test)] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:52\ntime:2019-10-22T09:30:01.579924 (delta: 0.024985)         elapsed: 4.085419  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"f81d110b68adb61b8825de7c3d7f4b3df1b501f8\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"c65861c9362d3c8439358c316152274c\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 413, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736601.6-15922123312454/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:63\ntime:2019-10-22T09:30:02.318670 (delta: 0.738727)         elapsed: 4.824165  \nfatal: [127.0.0.1]: FAILED! => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:00.386998\", \"end\": \"2019-10-22 09:30:02.841993\", \"failed_when_result\": true, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2019-10-22 09:30:02.454995\", \"stderr\": \"Error in configuration: \\n unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\\n unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\\n unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\", \"stderr_lines\": [\"Error in configuration: \", \" unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\", \" unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\", \" unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\"], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [set_fact] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:152\ntime:2019-10-22T09:30:02.869357 (delta: 0.550668)         elapsed: 5.374852  \nok: [127.0.0.1] => {\"ansible_facts\": {\"flag\": \"Fail\"}, \"changed\": false}\n``` \n\n## TASK [Generate the litmus result CR to reflect EOT (End of Test)] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:159\ntime:2019-10-22T09:30:02.902128 (delta: 0.032751)         elapsed: 5.407623  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"032fbf1a09bbe4384dc7ccf52080d9aeca806323\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"e125d36fb6e935332e127564201fb1e1\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 411, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736602.92-122613202543123/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:170\ntime:2019-10-22T09:30:03.500344 (delta: 0.598197)         elapsed: 6.005839  \nfatal: [127.0.0.1]: FAILED! => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:00.261548\", \"end\": \"2019-10-22 09:30:03.832748\", \"failed_when_result\": true, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2019-10-22 09:30:03.571200\", \"stderr\": \"Error in configuration: \\n unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\\n unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\\n unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\", \"stderr_lines\": [\"Error in configuration: \", \" unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\", \" unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\", \" unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\"], \"stdout\": \"\", \"stdout_lines\": []}\nPLAY RECAP \n7.0.0.1                  : \u001b[0;32mok=4    \u001b[0;33mchanged=2    unreachable=0    \u001b[0;31mfailed=2   \ntime:2019-10-22T09:30:03.847634 (delta: 0.347272)         elapsed: 6.353129  \namber: case test-kil-pod is going to finish...\namber: result would be available in CRD 'litmusresult' form. Use 'kubectl get lr' for details.\n``` \n"},{"title":"CommitID[634f70f71as2ba7]2019-10-23T22:24:28","tag":["recover","pod-delete"],"time":"2019-10-23 22:24:28","url":"/post/2019-10-23T22:24:28","thumb":"/contents/2019-10-23T22:24:28/thumb.jpg","content":"=== \n标题： CommitID[634f70f71as2ba7]2019-10-23T22:24:28\n标签： recover, pod-delete\n\n=== \n\n\n# Summary report \n| Task status | number |\n| ------------ | ------------ |\n|      ok |      29\n|      change |      19\n|      unreachable |      0\n|      failed |      0\n# Info report \n ``` \namber: load the executor...\nci-enhanced: Pulling from diamond/service-providers/ansible-runner\nDigest: sha256:9b0d9b5684fd4d47abd9d45c016fd5ff835b1f810583b3e67886ca7c9bc0b877\nStatus: Image is up to date for registry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\nregistry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\namber: found the case.\namber: the executor is running...\nansible-playbook 2.7.3\n  config file = None\n  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/local/lib/python2.7/dist-packages/ansible\n  executable location = /usr/local/bin/ansible-playbook\n  python version = 2.7.15+ (default, Nov 27 2018, 23:36:35) [GCC 7.3.0]\nNo config file found; using defaults\n/etc/ansible/hosts did not meet host_list requirements, check plugin documentation if this is unexpected\n/etc/ansible/hosts did not meet script requirements, check plugin documentation if this is unexpected\nPLAYBOOK: test.yml \n plays in ./experiments/chaos/app-pod-failure/test.yml\nPLAY [localhost] \ntime:2019-10-22T09:32:35.674168 (delta: 0.040952)         elapsed: 0.040952  \n``` \n\n## TASK [Gathering Facts] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:2\ntime:2019-10-22T09:32:35.683676 (delta: 0.009465)         elapsed: 0.05046  \nok: [127.0.0.1]\nMETA: ran handlers\n``` \n\n## TASK [Setup] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:22\ntime:2019-10-22T09:32:41.686005 (delta: 6.002295)         elapsed: 6.052789  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Checking status of liveness pod] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:29\ntime:2019-10-22T09:32:41.724829 (delta: 0.038804)         elapsed: 6.091613  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record test instance/run ID] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:42\ntime:2019-10-22T09:32:41.761581 (delta: 0.036722)         elapsed: 6.128365  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Construct testname appended with runID] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:46\ntime:2019-10-22T09:32:41.798056 (delta: 0.036451)         elapsed: 6.16484  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Generate the litmus result CR to reflect SOT (Start of Test)] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:52\ntime:2019-10-22T09:32:41.837476 (delta: 0.039398)         elapsed: 6.20426  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"65f1f8950b2a825fd3c27f66a8ec4113524d53c0\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"5324f15d0d02e6175cce9e8a64219dfe\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 416, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736761.86-229086193671283/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:63\ntime:2019-10-22T09:32:42.227249 (delta: 0.389733)         elapsed: 6.594033  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:01.339873\", \"end\": \"2019-10-22 09:32:43.753129\", \"failed_when_result\": false, \"rc\": 0, \"start\": \"2019-10-22 09:32:42.413256\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"litmusresult.litmus.io/app-pod-failure created\", \"stdout_lines\": [\"litmusresult.litmus.io/app-pod-failure created\"]}\n``` \n\n## TASK [Display the app information passed via the test job] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:72\ntime:2019-10-22T09:32:43.800883 (delta: 1.573613)         elapsed: 8.167667  \nok: [127.0.0.1] => {\n    \"msg\": [\n        \"The application info is as follows:\", \n        \"Namespace    : default\", \n        \"Label        : statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0\"\n    ]\n}\n``` \n\n## TASK [Verify that the AUT is running] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:80\ntime:2019-10-22T09:32:43.864344 (delta: 0.063425)         elapsed: 8.231128  \nincluded: /utils/k8s/check_deployment_status.yml for 127.0.0.1\n``` \n\n## TASK [Check the pod status] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:8\ntime:2019-10-22T09:32:43.929680 (delta: 0.065294)         elapsed: 8.296464  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [obtain the number of replicas.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:22\ntime:2019-10-22T09:32:43.968507 (delta: 0.038789)         elapsed: 8.335291  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:spec.replicas\", \"delta\": \"0:00:00.446878\", \"end\": \"2019-10-22 09:32:44.528493\", \"rc\": 0, \"start\": \"2019-10-22 09:32:44.081615\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Obtain the ready replica count and compare with the replica count.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:29\ntime:2019-10-22T09:32:44.566536 (delta: 0.598006)         elapsed: 8.93332  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:..readyReplicas\", \"delta\": \"0:00:00.456628\", \"end\": \"2019-10-22 09:32:45.138732\", \"rc\": 0, \"start\": \"2019-10-22 09:32:44.682104\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Get application pod name] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:84\ntime:2019-10-22T09:32:45.177247 (delta: 0.61069)         elapsed: 9.544031  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [include_tasks] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:94\ntime:2019-10-22T09:32:45.218924 (delta: 0.041646)         elapsed: 9.585708  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Get application pod name] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:105\ntime:2019-10-22T09:32:45.256949 (delta: 0.037995)         elapsed: 9.623733  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o jsonpath='{.items[0].metadata.name}'\", \"delta\": \"0:00:00.465754\", \"end\": \"2019-10-22 09:32:45.826833\", \"rc\": 0, \"start\": \"2019-10-22 09:32:45.361079\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"cass-demo-dc1-rack1-0\", \"stdout_lines\": [\"cass-demo-dc1-rack1-0\"]}\n``` \n\n## TASK [include_tasks] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:114\ntime:2019-10-22T09:32:45.861121 (delta: 0.604145)         elapsed: 10.227905  \nincluded: /chaoslib/pumba/pod_failure_by_sigkill.yaml for 127.0.0.1\n``` \n\n## TASK [Setup pumba chaos infrastructure] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:4\ntime:2019-10-22T09:32:45.973179 (delta: 0.112037)         elapsed: 10.339963  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl apply -f /chaoslib/pumba/pumba_kube.yaml -n default\", \"delta\": \"0:00:00.570165\", \"end\": \"2019-10-22 09:32:46.653936\", \"rc\": 0, \"start\": \"2019-10-22 09:32:46.083771\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"daemonset.extensions/pumba created\", \"stdout_lines\": [\"daemonset.extensions/pumba created\"]}\n``` \n\n## TASK [Confirm that the pumba ds is running on all nodes] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:13\ntime:2019-10-22T09:32:46.695020 (delta: 0.721818)         elapsed: 11.061804  \nFAILED - RETRYING: Confirm that the pumba ds is running on all nodes (60 retries left).\nFAILED - RETRYING: Confirm that the pumba ds is running on all nodes (59 retries left).\nchanged: [127.0.0.1] => {\"attempts\": 3, \"changed\": true, \"cmd\": \"kubectl get pod -l app=pumba --no-headers -o custom-columns=:status.phase -n default | sort | uniq\", \"delta\": \"0:00:00.442172\", \"end\": \"2019-10-22 09:32:50.461738\", \"rc\": 0, \"start\": \"2019-10-22 09:32:50.019566\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"Running\", \"stdout_lines\": [\"Running\"]}\n``` \n\n## TASK [Select the app pod] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:27\ntime:2019-10-22T09:32:50.496854 (delta: 3.801803)         elapsed: 14.863638  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:36\ntime:2019-10-22T09:32:50.538436 (delta: 0.041559)         elapsed: 14.90522  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:43\ntime:2019-10-22T09:32:50.579263 (delta: 0.040803)         elapsed: 14.946047  \nok: [127.0.0.1] => {\"ansible_facts\": {\"app_pod_ut\": \"cass-demo-dc1-rack1-0\"}, \"changed\": false}\n``` \n\n## TASK [Identify the application node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:49\ntime:2019-10-22T09:32:50.638684 (delta: 0.059401)         elapsed: 15.005468  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod cass-demo-dc1-rack1-0 -n default --no-headers -o custom-columns=:spec.nodeName\", \"delta\": \"0:00:00.437792\", \"end\": \"2019-10-22 09:32:51.176349\", \"rc\": 0, \"start\": \"2019-10-22 09:32:50.738557\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"minikube\", \"stdout_lines\": [\"minikube\"]}\n``` \n\n## TASK [Record the application node name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:57\ntime:2019-10-22T09:32:51.209999 (delta: 0.571294)         elapsed: 15.576783  \nok: [127.0.0.1] => {\"ansible_facts\": {\"app_node\": \"minikube\"}, \"changed\": false}\n``` \n\n## TASK [Record the application container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:63\ntime:2019-10-22T09:32:51.270142 (delta: 0.060122)         elapsed: 15.636926  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pods -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -n default -o jsonpath='{.items[0].spec.containers[0].name}'\", \"delta\": \"0:00:00.439683\", \"end\": \"2019-10-22 09:32:51.814367\", \"rc\": 0, \"start\": \"2019-10-22 09:32:51.374684\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"cassandra\", \"stdout_lines\": [\"cassandra\"]}\n``` \n\n## TASK [Record the app_container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:70\ntime:2019-10-22T09:32:51.847909 (delta: 0.577746)         elapsed: 16.214693  \nok: [127.0.0.1] => {\"ansible_facts\": {\"app_container\": \"cassandra\"}, \"changed\": false}\n``` \n\n## TASK [Record the pumba pod on app node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:76\ntime:2019-10-22T09:32:51.907859 (delta: 0.059927)         elapsed: 16.274643  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod -l app=pumba -o wide -n default | grep minikube | awk '{print $1}'\", \"delta\": \"0:00:00.457465\", \"end\": \"2019-10-22 09:32:52.463953\", \"rc\": 0, \"start\": \"2019-10-22 09:32:52.006488\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"pumba-m9fhv\", \"stdout_lines\": [\"pumba-m9fhv\"]}\n``` \n\n## TASK [Record restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:85\ntime:2019-10-22T09:32:52.497435 (delta: 0.589554)         elapsed: 16.864219  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod cass-demo-dc1-rack1-0 -n default -o=jsonpath='{.status.containerStatuses[?(@.name==\\\"cassandra\\\")].restartCount}'\", \"delta\": \"0:00:00.445335\", \"end\": \"2019-10-22 09:32:53.043548\", \"rc\": 0, \"start\": \"2019-10-22 09:32:52.598213\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"5\", \"stdout_lines\": [\"5\"]}\n``` \n\n## TASK [Force kill the application pod using pumba] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:93\ntime:2019-10-22T09:32:53.077400 (delta: 0.579931)         elapsed: 17.444184  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl exec pumba-m9fhv -n default -- pumba kill --signal SIGKILL re2:k8s_cassandra_;\", \"delta\": \"0:00:02.174077\", \"end\": \"2019-10-22 09:32:55.351290\", \"rc\": 0, \"start\": \"2019-10-22 09:32:53.177213\", \"stderr\": \"time=\\\"2019-10-22T09:32:53Z\\\" level=info msg=\\\"Kill containers\\\" \\ntime=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-1_default_af292200-2d06-4f19-9970-e64d00ed8302_5 (adf6e7b0f6a8c4e23be92ac5f291e8809bd47205716f55252db121313be4dd00) with signal SIGKILL\\\" \\ntime=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-0_default_3fcd5226-3229-4deb-9930-279e6eec50cc_5 (f84f21e935ce22b26c8c4053354726b34e515e94f64b27e3e0564c929e1472f4) with signal SIGKILL\\\" \", \"stderr_lines\": [\"time=\\\"2019-10-22T09:32:53Z\\\" level=info msg=\\\"Kill containers\\\" \", \"time=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-1_default_af292200-2d06-4f19-9970-e64d00ed8302_5 (adf6e7b0f6a8c4e23be92ac5f291e8809bd47205716f55252db121313be4dd00) with signal SIGKILL\\\" \", \"time=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-0_default_3fcd5226-3229-4deb-9930-279e6eec50cc_5 (f84f21e935ce22b26c8c4053354726b34e515e94f64b27e3e0564c929e1472f4) with signal SIGKILL\\\" \"], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Verify restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:102\ntime:2019-10-22T09:32:55.389173 (delta: 2.311746)         elapsed: 19.755957  \nFAILED - RETRYING: Verify restartCount (30 retries left).\nchanged: [127.0.0.1] => {\"attempts\": 2, \"changed\": true, \"cmd\": \"kubectl get pod cass-demo-dc1-rack1-0 -n default -o=jsonpath='{.status.containerStatuses[?(@.name==\\\"cassandra\\\")].restartCount}'\", \"delta\": \"0:00:00.471000\", \"end\": \"2019-10-22 09:32:58.525225\", \"rc\": 0, \"start\": \"2019-10-22 09:32:58.054225\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"6\", \"stdout_lines\": [\"6\"]}\n``` \n\n## TASK [Check if pumba is indeed running] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:117\ntime:2019-10-22T09:32:58.565366 (delta: 3.176158)         elapsed: 22.93215  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Delete the pumba daemonset] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:132\ntime:2019-10-22T09:32:58.617708 (delta: 0.052315)         elapsed: 22.984492  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Confirm that the pumba ds is deleted successfully] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:139\ntime:2019-10-22T09:32:58.658968 (delta: 0.041197)         elapsed: 23.025752  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Checkpoint] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:127\ntime:2019-10-22T09:32:58.702607 (delta: 0.043593)         elapsed: 23.069391  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Verify AUT liveness post fault-injection] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:134\ntime:2019-10-22T09:32:58.746531 (delta: 0.043879)         elapsed: 23.113315  \nincluded: /utils/k8s/check_deployment_status.yml for 127.0.0.1\n``` \n\n## TASK [Check the pod status] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:8\ntime:2019-10-22T09:32:58.808217 (delta: 0.061654)         elapsed: 23.175001  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [obtain the number of replicas.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:22\ntime:2019-10-22T09:32:58.850771 (delta: 0.042514)         elapsed: 23.217555  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:spec.replicas\", \"delta\": \"0:00:00.487258\", \"end\": \"2019-10-22 09:32:59.454084\", \"rc\": 0, \"start\": \"2019-10-22 09:32:58.966826\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Obtain the ready replica count and compare with the replica count.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:29\ntime:2019-10-22T09:32:59.502144 (delta: 0.651351)         elapsed: 23.868928  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:..readyReplicas\", \"delta\": \"0:00:00.460006\", \"end\": \"2019-10-22 09:33:00.079589\", \"rc\": 0, \"start\": \"2019-10-22 09:32:59.619583\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Checking status of liveness pod] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:139\ntime:2019-10-22T09:33:00.131823 (delta: 0.629637)         elapsed: 24.498607  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [set_fact] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:148\ntime:2019-10-22T09:33:00.169972 (delta: 0.038111)         elapsed: 24.536756  \nok: [127.0.0.1] => {\"ansible_facts\": {\"flag\": \"Pass\"}, \"changed\": false}\n``` \n\n## TASK [Generate the litmus result CR to reflect EOT (End of Test)] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:159\ntime:2019-10-22T09:33:00.230381 (delta: 0.060385)         elapsed: 24.597165  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"0ce715eedb8ca906ea535c15dc4cf27e5c351360\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"e9d551b88b01b393b3e36a1afeb12822\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 414, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736780.27-79185624627260/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:170\ntime:2019-10-22T09:33:01.259316 (delta: 1.028891)         elapsed: 25.6261  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:00.680528\", \"end\": \"2019-10-22 09:33:02.041191\", \"failed_when_result\": false, \"rc\": 0, \"start\": \"2019-10-22 09:33:01.360663\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"litmusresult.litmus.io/app-pod-failure configured\", \"stdout_lines\": [\"litmusresult.litmus.io/app-pod-failure configured\"]}\n``` \n\n## TASK [include_tasks] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:177\ntime:2019-10-22T09:33:02.082162 (delta: 0.822823)         elapsed: 26.448946  \nincluded: /chaoslib/pumba/pod_failure_by_sigkill.yaml for 127.0.0.1\n``` \n\n## TASK [Setup pumba chaos infrastructure] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:4\ntime:2019-10-22T09:33:02.167201 (delta: 0.084983)         elapsed: 26.533985  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Confirm that the pumba ds is running on all nodes] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:13\ntime:2019-10-22T09:33:02.210265 (delta: 0.043041)         elapsed: 26.577049  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Select the app pod] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:27\ntime:2019-10-22T09:33:02.246121 (delta: 0.035817)         elapsed: 26.612905  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:36\ntime:2019-10-22T09:33:02.279515 (delta: 0.033368)         elapsed: 26.646299  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:43\ntime:2019-10-22T09:33:02.313912 (delta: 0.034359)         elapsed: 26.680696  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Identify the application node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:49\ntime:2019-10-22T09:33:02.348276 (delta: 0.034334)         elapsed: 26.71506  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the application node name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:57\ntime:2019-10-22T09:33:02.382690 (delta: 0.034383)         elapsed: 26.749474  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the application container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:63\ntime:2019-10-22T09:33:02.423818 (delta: 0.041072)         elapsed: 26.790602  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the app_container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:70\ntime:2019-10-22T09:33:02.460732 (delta: 0.036856)         elapsed: 26.827516  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the pumba pod on app node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:76\ntime:2019-10-22T09:33:02.524203 (delta: 0.06345)         elapsed: 26.890987  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:85\ntime:2019-10-22T09:33:02.581366 (delta: 0.057111)         elapsed: 26.94815  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Force kill the application pod using pumba] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:93\ntime:2019-10-22T09:33:02.624084 (delta: 0.042667)         elapsed: 26.990868  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Verify restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:102\ntime:2019-10-22T09:33:02.656630 (delta: 0.032513)         elapsed: 27.023414  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Check if pumba is indeed running] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:117\ntime:2019-10-22T09:33:02.694621 (delta: 0.037969)         elapsed: 27.061405  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get pod -l app=pumba --no-headers -o custom-columns=:status.phase -n default | sort | uniq\", \"delta\": \"0:00:00.474286\", \"end\": \"2019-10-22 09:33:03.279996\", \"rc\": 0, \"start\": \"2019-10-22 09:33:02.805710\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"Running\", \"stdout_lines\": [\"Running\"]}\n``` \n\n## TASK [Delete the pumba daemonset] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:132\ntime:2019-10-22T09:33:03.322117 (delta: 0.627443)         elapsed: 27.688901  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl delete -f /chaoslib/pumba/pumba_kube.yaml -n default\", \"delta\": \"0:00:00.497277\", \"end\": \"2019-10-22 09:33:03.942872\", \"rc\": 0, \"start\": \"2019-10-22 09:33:03.445595\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"daemonset.extensions \\\"pumba\\\" deleted\", \"stdout_lines\": [\"daemonset.extensions \\\"pumba\\\" deleted\"]}\n``` \n\n## TASK [Confirm that the pumba ds is deleted successfully] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:139\ntime:2019-10-22T09:33:03.978190 (delta: 0.656028)         elapsed: 28.344974  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Cleanup] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:186\ntime:2019-10-22T09:33:04.018832 (delta: 0.040603)         elapsed: 28.385616  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\nMETA: ran handlers\nMETA: ran handlers\nPLAY RECAP \n7.0.0.1\u001b[0m                  : \u001b[0;32mok=29  \u001b[0m \u001b[0;33mchanged=19  \u001b[0m unreachable=0    failed=0   \ntime:2019-10-22T09:33:04.045610 (delta: 0.026746)         elapsed: 28.412394  \namber: case app-pod-failure is going to finish...\namber: result would be available in CRD 'litmusresult' form. Use 'kubectl get lr' for details.\n``` \n"},{"title":"CommitID[98f70f71652ba7]2019-10-24T09:32:03","tag":["mem-luck","full-cpu"],"time":"2019-10-24 09:32:03","url":"/post/2019-10-24T09:32:03","thumb":"/contents/2019-10-24T09:32:03/thumb.jpg","content":"=== \n标题： CommitID[98f70f71652ba7]2019-10-24T09:32:03\n标签： mem-luck, full-cpu\n\n=== \n\n\n# Summary report \n| Task status | number |\n| ------------ | ------------ |\n|      ok |      4\n|      change |      2\n|      unreachable |      0\n|      failed |      2\n# Info report \n ``` \namber: load the executor...\nci-enhanced: Pulling from diamond/service-providers/ansible-runner\nDigest: sha256:9b0d9b5684fd4d47abd9d45c016fd5ff835b1f810583b3e67886ca7c9bc0b877\nStatus: Image is up to date for registry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\nregistry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\namber: found the case.\namber: the executor is running...\nansible-playbook 2.7.3\n  config file = None\n  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/local/lib/python2.7/dist-packages/ansible\n  executable location = /usr/local/bin/ansible-playbook\n  python version = 2.7.15+ (default, Nov 27 2018, 23:36:35) [GCC 7.3.0]\nNo config file found; using defaults\n/etc/ansible/hosts did not meet host_list requirements, check plugin documentation if this is unexpected\n/etc/ansible/hosts did not meet script requirements, check plugin documentation if this is unexpected\nPLAYBOOK: test.yml \n plays in ./experiments/chaos/test-kil-pod/test.yml\nPLAY [localhost] \ntime:2019-10-22T09:29:57.520349 (delta: 0.025844)         elapsed: 0.025844  \n``` \n\n## TASK [Gathering Facts] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:2\ntime:2019-10-22T09:29:57.525821 (delta: 0.005457)         elapsed: 0.031316  \nok: [127.0.0.1]\nMETA: ran handlers\n``` \n\n## TASK [Setup] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:22\ntime:2019-10-22T09:30:01.478122 (delta: 3.952288)         elapsed: 3.983617  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Checking status of liveness pod] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:29\ntime:2019-10-22T09:30:01.504660 (delta: 0.026522)         elapsed: 4.010155  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record test instance/run ID] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:42\ntime:2019-10-22T09:30:01.529959 (delta: 0.025251)         elapsed: 4.035454  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Construct testname appended with runID] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:46\ntime:2019-10-22T09:30:01.554921 (delta: 0.024944)         elapsed: 4.060416  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Generate the litmus result CR to reflect SOT (Start of Test)] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:52\ntime:2019-10-22T09:30:01.579924 (delta: 0.024985)         elapsed: 4.085419  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"f81d110b68adb61b8825de7c3d7f4b3df1b501f8\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"c65861c9362d3c8439358c316152274c\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 413, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736601.6-15922123312454/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:63\ntime:2019-10-22T09:30:02.318670 (delta: 0.738727)         elapsed: 4.824165  \nfatal: [127.0.0.1]: FAILED! => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:00.386998\", \"end\": \"2019-10-22 09:30:02.841993\", \"failed_when_result\": true, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2019-10-22 09:30:02.454995\", \"stderr\": \"Error in configuration: \\n unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\\n unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\\n unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\", \"stderr_lines\": [\"Error in configuration: \", \" unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\", \" unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\", \" unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\"], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [set_fact] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:152\ntime:2019-10-22T09:30:02.869357 (delta: 0.550668)         elapsed: 5.374852  \nok: [127.0.0.1] => {\"ansible_facts\": {\"flag\": \"Fail\"}, \"changed\": false}\n``` \n\n## TASK [Generate the litmus result CR to reflect EOT (End of Test)] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:159\ntime:2019-10-22T09:30:02.902128 (delta: 0.032751)         elapsed: 5.407623  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"032fbf1a09bbe4384dc7ccf52080d9aeca806323\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"e125d36fb6e935332e127564201fb1e1\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 411, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736602.92-122613202543123/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:170\ntime:2019-10-22T09:30:03.500344 (delta: 0.598197)         elapsed: 6.005839  \nfatal: [127.0.0.1]: FAILED! => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:00.261548\", \"end\": \"2019-10-22 09:30:03.832748\", \"failed_when_result\": true, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2019-10-22 09:30:03.571200\", \"stderr\": \"Error in configuration: \\n unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\\n unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\\n unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\", \"stderr_lines\": [\"Error in configuration: \", \" unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\", \" unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\", \" unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\"], \"stdout\": \"\", \"stdout_lines\": []}\nPLAY RECAP \n7.0.0.1                  : \u001b[0;32mok=4    \u001b[0;33mchanged=2    unreachable=0    \u001b[0;31mfailed=2   \ntime:2019-10-22T09:30:03.847634 (delta: 0.347272)         elapsed: 6.353129  \namber: case test-kil-pod is going to finish...\namber: result would be available in CRD 'litmusresult' form. Use 'kubectl get lr' for details.\n``` \n"},{"title":"CommitID[65f70f71492ba7]2019-10-24T10:20:23","tag":["ful-cpu"],"time":"2019-10-24 10:20:23","url":"/post/2019-10-24T10:20:23","thumb":"/contents/2019-10-24T10:20:23/thumb.jpg","content":"=== \n标题： CommitID[65f70f71492ba7]2019-10-24T10:20:23\n标签： ful-cpu\n\n=== \n\n\n# Summary report \n| Task status | number |\n| ------------ | ------------ |\n|      ok |      29\n|      change |      19\n|      unreachable |      0\n|      failed |      0\n# Info report \n ``` \namber: load the executor...\nci-enhanced: Pulling from diamond/service-providers/ansible-runner\nDigest: sha256:9b0d9b5684fd4d47abd9d45c016fd5ff835b1f810583b3e67886ca7c9bc0b877\nStatus: Image is up to date for registry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\nregistry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\namber: found the case.\namber: the executor is running...\nansible-playbook 2.7.3\n  config file = None\n  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/local/lib/python2.7/dist-packages/ansible\n  executable location = /usr/local/bin/ansible-playbook\n  python version = 2.7.15+ (default, Nov 27 2018, 23:36:35) [GCC 7.3.0]\nNo config file found; using defaults\n/etc/ansible/hosts did not meet host_list requirements, check plugin documentation if this is unexpected\n/etc/ansible/hosts did not meet script requirements, check plugin documentation if this is unexpected\nPLAYBOOK: test.yml \n plays in ./experiments/chaos/app-pod-failure/test.yml\nPLAY [localhost] \ntime:2019-10-22T09:32:35.674168 (delta: 0.040952)         elapsed: 0.040952  \n``` \n\n## TASK [Gathering Facts] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:2\ntime:2019-10-22T09:32:35.683676 (delta: 0.009465)         elapsed: 0.05046  \nok: [127.0.0.1]\nMETA: ran handlers\n``` \n\n## TASK [Setup] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:22\ntime:2019-10-22T09:32:41.686005 (delta: 6.002295)         elapsed: 6.052789  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Checking status of liveness pod] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:29\ntime:2019-10-22T09:32:41.724829 (delta: 0.038804)         elapsed: 6.091613  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record test instance/run ID] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:42\ntime:2019-10-22T09:32:41.761581 (delta: 0.036722)         elapsed: 6.128365  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Construct testname appended with runID] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:46\ntime:2019-10-22T09:32:41.798056 (delta: 0.036451)         elapsed: 6.16484  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Generate the litmus result CR to reflect SOT (Start of Test)] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:52\ntime:2019-10-22T09:32:41.837476 (delta: 0.039398)         elapsed: 6.20426  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"65f1f8950b2a825fd3c27f66a8ec4113524d53c0\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"5324f15d0d02e6175cce9e8a64219dfe\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 416, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736761.86-229086193671283/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:63\ntime:2019-10-22T09:32:42.227249 (delta: 0.389733)         elapsed: 6.594033  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:01.339873\", \"end\": \"2019-10-22 09:32:43.753129\", \"failed_when_result\": false, \"rc\": 0, \"start\": \"2019-10-22 09:32:42.413256\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"litmusresult.litmus.io/app-pod-failure created\", \"stdout_lines\": [\"litmusresult.litmus.io/app-pod-failure created\"]}\n``` \n\n## TASK [Display the app information passed via the test job] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:72\ntime:2019-10-22T09:32:43.800883 (delta: 1.573613)         elapsed: 8.167667  \nok: [127.0.0.1] => {\n    \"msg\": [\n        \"The application info is as follows:\", \n        \"Namespace    : default\", \n        \"Label        : statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0\"\n    ]\n}\n``` \n\n## TASK [Verify that the AUT is running] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:80\ntime:2019-10-22T09:32:43.864344 (delta: 0.063425)         elapsed: 8.231128  \nincluded: /utils/k8s/check_deployment_status.yml for 127.0.0.1\n``` \n\n## TASK [Check the pod status] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:8\ntime:2019-10-22T09:32:43.929680 (delta: 0.065294)         elapsed: 8.296464  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [obtain the number of replicas.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:22\ntime:2019-10-22T09:32:43.968507 (delta: 0.038789)         elapsed: 8.335291  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:spec.replicas\", \"delta\": \"0:00:00.446878\", \"end\": \"2019-10-22 09:32:44.528493\", \"rc\": 0, \"start\": \"2019-10-22 09:32:44.081615\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Obtain the ready replica count and compare with the replica count.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:29\ntime:2019-10-22T09:32:44.566536 (delta: 0.598006)         elapsed: 8.93332  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:..readyReplicas\", \"delta\": \"0:00:00.456628\", \"end\": \"2019-10-22 09:32:45.138732\", \"rc\": 0, \"start\": \"2019-10-22 09:32:44.682104\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Get application pod name] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:84\ntime:2019-10-22T09:32:45.177247 (delta: 0.61069)         elapsed: 9.544031  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [include_tasks] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:94\ntime:2019-10-22T09:32:45.218924 (delta: 0.041646)         elapsed: 9.585708  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Get application pod name] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:105\ntime:2019-10-22T09:32:45.256949 (delta: 0.037995)         elapsed: 9.623733  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o jsonpath='{.items[0].metadata.name}'\", \"delta\": \"0:00:00.465754\", \"end\": \"2019-10-22 09:32:45.826833\", \"rc\": 0, \"start\": \"2019-10-22 09:32:45.361079\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"cass-demo-dc1-rack1-0\", \"stdout_lines\": [\"cass-demo-dc1-rack1-0\"]}\n``` \n\n## TASK [include_tasks] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:114\ntime:2019-10-22T09:32:45.861121 (delta: 0.604145)         elapsed: 10.227905  \nincluded: /chaoslib/pumba/pod_failure_by_sigkill.yaml for 127.0.0.1\n``` \n\n## TASK [Setup pumba chaos infrastructure] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:4\ntime:2019-10-22T09:32:45.973179 (delta: 0.112037)         elapsed: 10.339963  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl apply -f /chaoslib/pumba/pumba_kube.yaml -n default\", \"delta\": \"0:00:00.570165\", \"end\": \"2019-10-22 09:32:46.653936\", \"rc\": 0, \"start\": \"2019-10-22 09:32:46.083771\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"daemonset.extensions/pumba created\", \"stdout_lines\": [\"daemonset.extensions/pumba created\"]}\n``` \n\n## TASK [Confirm that the pumba ds is running on all nodes] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:13\ntime:2019-10-22T09:32:46.695020 (delta: 0.721818)         elapsed: 11.061804  \nFAILED - RETRYING: Confirm that the pumba ds is running on all nodes (60 retries left).\nFAILED - RETRYING: Confirm that the pumba ds is running on all nodes (59 retries left).\nchanged: [127.0.0.1] => {\"attempts\": 3, \"changed\": true, \"cmd\": \"kubectl get pod -l app=pumba --no-headers -o custom-columns=:status.phase -n default | sort | uniq\", \"delta\": \"0:00:00.442172\", \"end\": \"2019-10-22 09:32:50.461738\", \"rc\": 0, \"start\": \"2019-10-22 09:32:50.019566\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"Running\", \"stdout_lines\": [\"Running\"]}\n``` \n\n## TASK [Select the app pod] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:27\ntime:2019-10-22T09:32:50.496854 (delta: 3.801803)         elapsed: 14.863638  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:36\ntime:2019-10-22T09:32:50.538436 (delta: 0.041559)         elapsed: 14.90522  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:43\ntime:2019-10-22T09:32:50.579263 (delta: 0.040803)         elapsed: 14.946047  \nok: [127.0.0.1] => {\"ansible_facts\": {\"app_pod_ut\": \"cass-demo-dc1-rack1-0\"}, \"changed\": false}\n``` \n\n## TASK [Identify the application node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:49\ntime:2019-10-22T09:32:50.638684 (delta: 0.059401)         elapsed: 15.005468  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod cass-demo-dc1-rack1-0 -n default --no-headers -o custom-columns=:spec.nodeName\", \"delta\": \"0:00:00.437792\", \"end\": \"2019-10-22 09:32:51.176349\", \"rc\": 0, \"start\": \"2019-10-22 09:32:50.738557\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"minikube\", \"stdout_lines\": [\"minikube\"]}\n``` \n\n## TASK [Record the application node name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:57\ntime:2019-10-22T09:32:51.209999 (delta: 0.571294)         elapsed: 15.576783  \nok: [127.0.0.1] => {\"ansible_facts\": {\"app_node\": \"minikube\"}, \"changed\": false}\n``` \n\n## TASK [Record the application container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:63\ntime:2019-10-22T09:32:51.270142 (delta: 0.060122)         elapsed: 15.636926  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pods -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -n default -o jsonpath='{.items[0].spec.containers[0].name}'\", \"delta\": \"0:00:00.439683\", \"end\": \"2019-10-22 09:32:51.814367\", \"rc\": 0, \"start\": \"2019-10-22 09:32:51.374684\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"cassandra\", \"stdout_lines\": [\"cassandra\"]}\n``` \n\n## TASK [Record the app_container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:70\ntime:2019-10-22T09:32:51.847909 (delta: 0.577746)         elapsed: 16.214693  \nok: [127.0.0.1] => {\"ansible_facts\": {\"app_container\": \"cassandra\"}, \"changed\": false}\n``` \n\n## TASK [Record the pumba pod on app node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:76\ntime:2019-10-22T09:32:51.907859 (delta: 0.059927)         elapsed: 16.274643  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod -l app=pumba -o wide -n default | grep minikube | awk '{print $1}'\", \"delta\": \"0:00:00.457465\", \"end\": \"2019-10-22 09:32:52.463953\", \"rc\": 0, \"start\": \"2019-10-22 09:32:52.006488\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"pumba-m9fhv\", \"stdout_lines\": [\"pumba-m9fhv\"]}\n``` \n\n## TASK [Record restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:85\ntime:2019-10-22T09:32:52.497435 (delta: 0.589554)         elapsed: 16.864219  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod cass-demo-dc1-rack1-0 -n default -o=jsonpath='{.status.containerStatuses[?(@.name==\\\"cassandra\\\")].restartCount}'\", \"delta\": \"0:00:00.445335\", \"end\": \"2019-10-22 09:32:53.043548\", \"rc\": 0, \"start\": \"2019-10-22 09:32:52.598213\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"5\", \"stdout_lines\": [\"5\"]}\n``` \n\n## TASK [Force kill the application pod using pumba] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:93\ntime:2019-10-22T09:32:53.077400 (delta: 0.579931)         elapsed: 17.444184  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl exec pumba-m9fhv -n default -- pumba kill --signal SIGKILL re2:k8s_cassandra_;\", \"delta\": \"0:00:02.174077\", \"end\": \"2019-10-22 09:32:55.351290\", \"rc\": 0, \"start\": \"2019-10-22 09:32:53.177213\", \"stderr\": \"time=\\\"2019-10-22T09:32:53Z\\\" level=info msg=\\\"Kill containers\\\" \\ntime=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-1_default_af292200-2d06-4f19-9970-e64d00ed8302_5 (adf6e7b0f6a8c4e23be92ac5f291e8809bd47205716f55252db121313be4dd00) with signal SIGKILL\\\" \\ntime=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-0_default_3fcd5226-3229-4deb-9930-279e6eec50cc_5 (f84f21e935ce22b26c8c4053354726b34e515e94f64b27e3e0564c929e1472f4) with signal SIGKILL\\\" \", \"stderr_lines\": [\"time=\\\"2019-10-22T09:32:53Z\\\" level=info msg=\\\"Kill containers\\\" \", \"time=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-1_default_af292200-2d06-4f19-9970-e64d00ed8302_5 (adf6e7b0f6a8c4e23be92ac5f291e8809bd47205716f55252db121313be4dd00) with signal SIGKILL\\\" \", \"time=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-0_default_3fcd5226-3229-4deb-9930-279e6eec50cc_5 (f84f21e935ce22b26c8c4053354726b34e515e94f64b27e3e0564c929e1472f4) with signal SIGKILL\\\" \"], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Verify restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:102\ntime:2019-10-22T09:32:55.389173 (delta: 2.311746)         elapsed: 19.755957  \nFAILED - RETRYING: Verify restartCount (30 retries left).\nchanged: [127.0.0.1] => {\"attempts\": 2, \"changed\": true, \"cmd\": \"kubectl get pod cass-demo-dc1-rack1-0 -n default -o=jsonpath='{.status.containerStatuses[?(@.name==\\\"cassandra\\\")].restartCount}'\", \"delta\": \"0:00:00.471000\", \"end\": \"2019-10-22 09:32:58.525225\", \"rc\": 0, \"start\": \"2019-10-22 09:32:58.054225\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"6\", \"stdout_lines\": [\"6\"]}\n``` \n\n## TASK [Check if pumba is indeed running] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:117\ntime:2019-10-22T09:32:58.565366 (delta: 3.176158)         elapsed: 22.93215  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Delete the pumba daemonset] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:132\ntime:2019-10-22T09:32:58.617708 (delta: 0.052315)         elapsed: 22.984492  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Confirm that the pumba ds is deleted successfully] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:139\ntime:2019-10-22T09:32:58.658968 (delta: 0.041197)         elapsed: 23.025752  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Checkpoint] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:127\ntime:2019-10-22T09:32:58.702607 (delta: 0.043593)         elapsed: 23.069391  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Verify AUT liveness post fault-injection] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:134\ntime:2019-10-22T09:32:58.746531 (delta: 0.043879)         elapsed: 23.113315  \nincluded: /utils/k8s/check_deployment_status.yml for 127.0.0.1\n``` \n\n## TASK [Check the pod status] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:8\ntime:2019-10-22T09:32:58.808217 (delta: 0.061654)         elapsed: 23.175001  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [obtain the number of replicas.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:22\ntime:2019-10-22T09:32:58.850771 (delta: 0.042514)         elapsed: 23.217555  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:spec.replicas\", \"delta\": \"0:00:00.487258\", \"end\": \"2019-10-22 09:32:59.454084\", \"rc\": 0, \"start\": \"2019-10-22 09:32:58.966826\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Obtain the ready replica count and compare with the replica count.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:29\ntime:2019-10-22T09:32:59.502144 (delta: 0.651351)         elapsed: 23.868928  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:..readyReplicas\", \"delta\": \"0:00:00.460006\", \"end\": \"2019-10-22 09:33:00.079589\", \"rc\": 0, \"start\": \"2019-10-22 09:32:59.619583\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Checking status of liveness pod] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:139\ntime:2019-10-22T09:33:00.131823 (delta: 0.629637)         elapsed: 24.498607  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [set_fact] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:148\ntime:2019-10-22T09:33:00.169972 (delta: 0.038111)         elapsed: 24.536756  \nok: [127.0.0.1] => {\"ansible_facts\": {\"flag\": \"Pass\"}, \"changed\": false}\n``` \n\n## TASK [Generate the litmus result CR to reflect EOT (End of Test)] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:159\ntime:2019-10-22T09:33:00.230381 (delta: 0.060385)         elapsed: 24.597165  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"0ce715eedb8ca906ea535c15dc4cf27e5c351360\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"e9d551b88b01b393b3e36a1afeb12822\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 414, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736780.27-79185624627260/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:170\ntime:2019-10-22T09:33:01.259316 (delta: 1.028891)         elapsed: 25.6261  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:00.680528\", \"end\": \"2019-10-22 09:33:02.041191\", \"failed_when_result\": false, \"rc\": 0, \"start\": \"2019-10-22 09:33:01.360663\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"litmusresult.litmus.io/app-pod-failure configured\", \"stdout_lines\": [\"litmusresult.litmus.io/app-pod-failure configured\"]}\n``` \n\n## TASK [include_tasks] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:177\ntime:2019-10-22T09:33:02.082162 (delta: 0.822823)         elapsed: 26.448946  \nincluded: /chaoslib/pumba/pod_failure_by_sigkill.yaml for 127.0.0.1\n``` \n\n## TASK [Setup pumba chaos infrastructure] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:4\ntime:2019-10-22T09:33:02.167201 (delta: 0.084983)         elapsed: 26.533985  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Confirm that the pumba ds is running on all nodes] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:13\ntime:2019-10-22T09:33:02.210265 (delta: 0.043041)         elapsed: 26.577049  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Select the app pod] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:27\ntime:2019-10-22T09:33:02.246121 (delta: 0.035817)         elapsed: 26.612905  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:36\ntime:2019-10-22T09:33:02.279515 (delta: 0.033368)         elapsed: 26.646299  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:43\ntime:2019-10-22T09:33:02.313912 (delta: 0.034359)         elapsed: 26.680696  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Identify the application node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:49\ntime:2019-10-22T09:33:02.348276 (delta: 0.034334)         elapsed: 26.71506  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the application node name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:57\ntime:2019-10-22T09:33:02.382690 (delta: 0.034383)         elapsed: 26.749474  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the application container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:63\ntime:2019-10-22T09:33:02.423818 (delta: 0.041072)         elapsed: 26.790602  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the app_container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:70\ntime:2019-10-22T09:33:02.460732 (delta: 0.036856)         elapsed: 26.827516  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the pumba pod on app node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:76\ntime:2019-10-22T09:33:02.524203 (delta: 0.06345)         elapsed: 26.890987  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:85\ntime:2019-10-22T09:33:02.581366 (delta: 0.057111)         elapsed: 26.94815  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Force kill the application pod using pumba] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:93\ntime:2019-10-22T09:33:02.624084 (delta: 0.042667)         elapsed: 26.990868  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Verify restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:102\ntime:2019-10-22T09:33:02.656630 (delta: 0.032513)         elapsed: 27.023414  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Check if pumba is indeed running] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:117\ntime:2019-10-22T09:33:02.694621 (delta: 0.037969)         elapsed: 27.061405  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get pod -l app=pumba --no-headers -o custom-columns=:status.phase -n default | sort | uniq\", \"delta\": \"0:00:00.474286\", \"end\": \"2019-10-22 09:33:03.279996\", \"rc\": 0, \"start\": \"2019-10-22 09:33:02.805710\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"Running\", \"stdout_lines\": [\"Running\"]}\n``` \n\n## TASK [Delete the pumba daemonset] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:132\ntime:2019-10-22T09:33:03.322117 (delta: 0.627443)         elapsed: 27.688901  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl delete -f /chaoslib/pumba/pumba_kube.yaml -n default\", \"delta\": \"0:00:00.497277\", \"end\": \"2019-10-22 09:33:03.942872\", \"rc\": 0, \"start\": \"2019-10-22 09:33:03.445595\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"daemonset.extensions \\\"pumba\\\" deleted\", \"stdout_lines\": [\"daemonset.extensions \\\"pumba\\\" deleted\"]}\n``` \n\n## TASK [Confirm that the pumba ds is deleted successfully] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:139\ntime:2019-10-22T09:33:03.978190 (delta: 0.656028)         elapsed: 28.344974  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Cleanup] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:186\ntime:2019-10-22T09:33:04.018832 (delta: 0.040603)         elapsed: 28.385616  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\nMETA: ran handlers\nMETA: ran handlers\nPLAY RECAP \n7.0.0.1\u001b[0m                  : \u001b[0;32mok=29  \u001b[0m \u001b[0;33mchanged=19  \u001b[0m unreachable=0    failed=0   \ntime:2019-10-22T09:33:04.045610 (delta: 0.026746)         elapsed: 28.412394  \namber: case app-pod-failure is going to finish...\namber: result would be available in CRD 'litmusresult' form. Use 'kubectl get lr' for details.\n``` \n"},{"title":"CommitID[a6s468as70a6c]2019-10-24T10:32:03","tag":["app-pod-failure"],"time":"2019-10-24 10:32:03","url":"/post/2019-10-24T10:32:03","thumb":"/contents/2019-10-24T10:32:03/thumb.jpg","content":"=== \n标题： CommitID[a6s468as70a6c]2019-10-24T10:32:03\n标签： app-pod-failure\n\n=== \n\n\n# Summary report \n| Task status | number |\n| ------------ | ------------ |\n|      ok |      4\n|      change |      2\n|      unreachable |      0\n|      failed |      2\n# Info report \n ``` \namber: load the executor...\nci-enhanced: Pulling from diamond/service-providers/ansible-runner\nDigest: sha256:9b0d9b5684fd4d47abd9d45c016fd5ff835b1f810583b3e67886ca7c9bc0b877\nStatus: Image is up to date for registry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\nregistry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\namber: found the case.\namber: the executor is running...\nansible-playbook 2.7.3\n  config file = None\n  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/local/lib/python2.7/dist-packages/ansible\n  executable location = /usr/local/bin/ansible-playbook\n  python version = 2.7.15+ (default, Nov 27 2018, 23:36:35) [GCC 7.3.0]\nNo config file found; using defaults\n/etc/ansible/hosts did not meet host_list requirements, check plugin documentation if this is unexpected\n/etc/ansible/hosts did not meet script requirements, check plugin documentation if this is unexpected\nPLAYBOOK: test.yml \n plays in ./experiments/chaos/test-kil-pod/test.yml\nPLAY [localhost] \ntime:2019-10-22T09:29:57.520349 (delta: 0.025844)         elapsed: 0.025844  \n``` \n\n## TASK [Gathering Facts] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:2\ntime:2019-10-22T09:29:57.525821 (delta: 0.005457)         elapsed: 0.031316  \nok: [127.0.0.1]\nMETA: ran handlers\n``` \n\n## TASK [Setup] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:22\ntime:2019-10-22T09:30:01.478122 (delta: 3.952288)         elapsed: 3.983617  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Checking status of liveness pod] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:29\ntime:2019-10-22T09:30:01.504660 (delta: 0.026522)         elapsed: 4.010155  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record test instance/run ID] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:42\ntime:2019-10-22T09:30:01.529959 (delta: 0.025251)         elapsed: 4.035454  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Construct testname appended with runID] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:46\ntime:2019-10-22T09:30:01.554921 (delta: 0.024944)         elapsed: 4.060416  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Generate the litmus result CR to reflect SOT (Start of Test)] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:52\ntime:2019-10-22T09:30:01.579924 (delta: 0.024985)         elapsed: 4.085419  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"f81d110b68adb61b8825de7c3d7f4b3df1b501f8\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"c65861c9362d3c8439358c316152274c\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 413, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736601.6-15922123312454/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:63\ntime:2019-10-22T09:30:02.318670 (delta: 0.738727)         elapsed: 4.824165  \nfatal: [127.0.0.1]: FAILED! => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:00.386998\", \"end\": \"2019-10-22 09:30:02.841993\", \"failed_when_result\": true, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2019-10-22 09:30:02.454995\", \"stderr\": \"Error in configuration: \\n unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\\n unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\\n unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\", \"stderr_lines\": [\"Error in configuration: \", \" unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\", \" unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\", \" unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\"], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [set_fact] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:152\ntime:2019-10-22T09:30:02.869357 (delta: 0.550668)         elapsed: 5.374852  \nok: [127.0.0.1] => {\"ansible_facts\": {\"flag\": \"Fail\"}, \"changed\": false}\n``` \n\n## TASK [Generate the litmus result CR to reflect EOT (End of Test)] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:159\ntime:2019-10-22T09:30:02.902128 (delta: 0.032751)         elapsed: 5.407623  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"032fbf1a09bbe4384dc7ccf52080d9aeca806323\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"e125d36fb6e935332e127564201fb1e1\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 411, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736602.92-122613202543123/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/test-kil-pod/test.yml:170\ntime:2019-10-22T09:30:03.500344 (delta: 0.598197)         elapsed: 6.005839  \nfatal: [127.0.0.1]: FAILED! => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:00.261548\", \"end\": \"2019-10-22 09:30:03.832748\", \"failed_when_result\": true, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2019-10-22 09:30:03.571200\", \"stderr\": \"Error in configuration: \\n unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\\n unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\\n unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\", \"stderr_lines\": [\"Error in configuration: \", \" unable to read client-cert /home/SENSETIME/tangqing2/.minikube/client.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.crt: no such file or directory\", \" unable to read client-key /home/SENSETIME/tangqing2/.minikube/client.key for minikube due to open /home/SENSETIME/tangqing2/.minikube/client.key: no such file or directory\", \" unable to read certificate-authority /home/SENSETIME/tangqing2/.minikube/ca.crt for minikube due to open /home/SENSETIME/tangqing2/.minikube/ca.crt: no such file or directory\"], \"stdout\": \"\", \"stdout_lines\": []}\nPLAY RECAP \n7.0.0.1                  : \u001b[0;32mok=4    \u001b[0;33mchanged=2    unreachable=0    \u001b[0;31mfailed=2   \ntime:2019-10-22T09:30:03.847634 (delta: 0.347272)         elapsed: 6.353129  \namber: case test-kil-pod is going to finish...\namber: result would be available in CRD 'litmusresult' form. Use 'kubectl get lr' for details.\n``` \n"},{"title":"CommitID[9654682070a6c]2019-10-24T11:30:27","tag":["network-delay"],"time":"2019-10-24 11:30:27","url":"/post/2019-10-24T11:30:27","thumb":"/contents/2019-10-24T11:30:27/thumb.jpg","content":"=== \n标题： CommitID[9654682070a6c]2019-10-24T11:30:27\n标签： network-delay\n\n=== \n\n\n# Summary report \n| Task status | number |\n| ------------ | ------------ |\n|      ok |      29\n|      change |      19\n|      unreachable |      0\n|      failed |      0\n# Info report \n ``` \namber: load the executor...\nci-enhanced: Pulling from diamond/service-providers/ansible-runner\nDigest: sha256:9b0d9b5684fd4d47abd9d45c016fd5ff835b1f810583b3e67886ca7c9bc0b877\nStatus: Image is up to date for registry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\nregistry.sensetime.com/diamond/service-providers/ansible-runner:ci-enhanced\namber: found the case.\namber: the executor is running...\nansible-playbook 2.7.3\n  config file = None\n  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/local/lib/python2.7/dist-packages/ansible\n  executable location = /usr/local/bin/ansible-playbook\n  python version = 2.7.15+ (default, Nov 27 2018, 23:36:35) [GCC 7.3.0]\nNo config file found; using defaults\n/etc/ansible/hosts did not meet host_list requirements, check plugin documentation if this is unexpected\n/etc/ansible/hosts did not meet script requirements, check plugin documentation if this is unexpected\nPLAYBOOK: test.yml \n plays in ./experiments/chaos/app-pod-failure/test.yml\nPLAY [localhost] \ntime:2019-10-22T09:32:35.674168 (delta: 0.040952)         elapsed: 0.040952  \n``` \n\n## TASK [Gathering Facts] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:2\ntime:2019-10-22T09:32:35.683676 (delta: 0.009465)         elapsed: 0.05046  \nok: [127.0.0.1]\nMETA: ran handlers\n``` \n\n## TASK [Setup] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:22\ntime:2019-10-22T09:32:41.686005 (delta: 6.002295)         elapsed: 6.052789  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Checking status of liveness pod] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:29\ntime:2019-10-22T09:32:41.724829 (delta: 0.038804)         elapsed: 6.091613  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record test instance/run ID] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:42\ntime:2019-10-22T09:32:41.761581 (delta: 0.036722)         elapsed: 6.128365  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Construct testname appended with runID] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:46\ntime:2019-10-22T09:32:41.798056 (delta: 0.036451)         elapsed: 6.16484  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Generate the litmus result CR to reflect SOT (Start of Test)] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:52\ntime:2019-10-22T09:32:41.837476 (delta: 0.039398)         elapsed: 6.20426  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"65f1f8950b2a825fd3c27f66a8ec4113524d53c0\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"5324f15d0d02e6175cce9e8a64219dfe\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 416, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736761.86-229086193671283/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:63\ntime:2019-10-22T09:32:42.227249 (delta: 0.389733)         elapsed: 6.594033  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:01.339873\", \"end\": \"2019-10-22 09:32:43.753129\", \"failed_when_result\": false, \"rc\": 0, \"start\": \"2019-10-22 09:32:42.413256\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"litmusresult.litmus.io/app-pod-failure created\", \"stdout_lines\": [\"litmusresult.litmus.io/app-pod-failure created\"]}\n``` \n\n## TASK [Display the app information passed via the test job] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:72\ntime:2019-10-22T09:32:43.800883 (delta: 1.573613)         elapsed: 8.167667  \nok: [127.0.0.1] => {\n    \"msg\": [\n        \"The application info is as follows:\", \n        \"Namespace    : default\", \n        \"Label        : statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0\"\n    ]\n}\n``` \n\n## TASK [Verify that the AUT is running] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:80\ntime:2019-10-22T09:32:43.864344 (delta: 0.063425)         elapsed: 8.231128  \nincluded: /utils/k8s/check_deployment_status.yml for 127.0.0.1\n``` \n\n## TASK [Check the pod status] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:8\ntime:2019-10-22T09:32:43.929680 (delta: 0.065294)         elapsed: 8.296464  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [obtain the number of replicas.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:22\ntime:2019-10-22T09:32:43.968507 (delta: 0.038789)         elapsed: 8.335291  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:spec.replicas\", \"delta\": \"0:00:00.446878\", \"end\": \"2019-10-22 09:32:44.528493\", \"rc\": 0, \"start\": \"2019-10-22 09:32:44.081615\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Obtain the ready replica count and compare with the replica count.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:29\ntime:2019-10-22T09:32:44.566536 (delta: 0.598006)         elapsed: 8.93332  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:..readyReplicas\", \"delta\": \"0:00:00.456628\", \"end\": \"2019-10-22 09:32:45.138732\", \"rc\": 0, \"start\": \"2019-10-22 09:32:44.682104\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Get application pod name] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:84\ntime:2019-10-22T09:32:45.177247 (delta: 0.61069)         elapsed: 9.544031  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [include_tasks] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:94\ntime:2019-10-22T09:32:45.218924 (delta: 0.041646)         elapsed: 9.585708  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Get application pod name] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:105\ntime:2019-10-22T09:32:45.256949 (delta: 0.037995)         elapsed: 9.623733  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o jsonpath='{.items[0].metadata.name}'\", \"delta\": \"0:00:00.465754\", \"end\": \"2019-10-22 09:32:45.826833\", \"rc\": 0, \"start\": \"2019-10-22 09:32:45.361079\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"cass-demo-dc1-rack1-0\", \"stdout_lines\": [\"cass-demo-dc1-rack1-0\"]}\n``` \n\n## TASK [include_tasks] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:114\ntime:2019-10-22T09:32:45.861121 (delta: 0.604145)         elapsed: 10.227905  \nincluded: /chaoslib/pumba/pod_failure_by_sigkill.yaml for 127.0.0.1\n``` \n\n## TASK [Setup pumba chaos infrastructure] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:4\ntime:2019-10-22T09:32:45.973179 (delta: 0.112037)         elapsed: 10.339963  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl apply -f /chaoslib/pumba/pumba_kube.yaml -n default\", \"delta\": \"0:00:00.570165\", \"end\": \"2019-10-22 09:32:46.653936\", \"rc\": 0, \"start\": \"2019-10-22 09:32:46.083771\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"daemonset.extensions/pumba created\", \"stdout_lines\": [\"daemonset.extensions/pumba created\"]}\n``` \n\n## TASK [Confirm that the pumba ds is running on all nodes] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:13\ntime:2019-10-22T09:32:46.695020 (delta: 0.721818)         elapsed: 11.061804  \nFAILED - RETRYING: Confirm that the pumba ds is running on all nodes (60 retries left).\nFAILED - RETRYING: Confirm that the pumba ds is running on all nodes (59 retries left).\nchanged: [127.0.0.1] => {\"attempts\": 3, \"changed\": true, \"cmd\": \"kubectl get pod -l app=pumba --no-headers -o custom-columns=:status.phase -n default | sort | uniq\", \"delta\": \"0:00:00.442172\", \"end\": \"2019-10-22 09:32:50.461738\", \"rc\": 0, \"start\": \"2019-10-22 09:32:50.019566\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"Running\", \"stdout_lines\": [\"Running\"]}\n``` \n\n## TASK [Select the app pod] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:27\ntime:2019-10-22T09:32:50.496854 (delta: 3.801803)         elapsed: 14.863638  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:36\ntime:2019-10-22T09:32:50.538436 (delta: 0.041559)         elapsed: 14.90522  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:43\ntime:2019-10-22T09:32:50.579263 (delta: 0.040803)         elapsed: 14.946047  \nok: [127.0.0.1] => {\"ansible_facts\": {\"app_pod_ut\": \"cass-demo-dc1-rack1-0\"}, \"changed\": false}\n``` \n\n## TASK [Identify the application node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:49\ntime:2019-10-22T09:32:50.638684 (delta: 0.059401)         elapsed: 15.005468  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod cass-demo-dc1-rack1-0 -n default --no-headers -o custom-columns=:spec.nodeName\", \"delta\": \"0:00:00.437792\", \"end\": \"2019-10-22 09:32:51.176349\", \"rc\": 0, \"start\": \"2019-10-22 09:32:50.738557\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"minikube\", \"stdout_lines\": [\"minikube\"]}\n``` \n\n## TASK [Record the application node name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:57\ntime:2019-10-22T09:32:51.209999 (delta: 0.571294)         elapsed: 15.576783  \nok: [127.0.0.1] => {\"ansible_facts\": {\"app_node\": \"minikube\"}, \"changed\": false}\n``` \n\n## TASK [Record the application container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:63\ntime:2019-10-22T09:32:51.270142 (delta: 0.060122)         elapsed: 15.636926  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pods -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -n default -o jsonpath='{.items[0].spec.containers[0].name}'\", \"delta\": \"0:00:00.439683\", \"end\": \"2019-10-22 09:32:51.814367\", \"rc\": 0, \"start\": \"2019-10-22 09:32:51.374684\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"cassandra\", \"stdout_lines\": [\"cassandra\"]}\n``` \n\n## TASK [Record the app_container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:70\ntime:2019-10-22T09:32:51.847909 (delta: 0.577746)         elapsed: 16.214693  \nok: [127.0.0.1] => {\"ansible_facts\": {\"app_container\": \"cassandra\"}, \"changed\": false}\n``` \n\n## TASK [Record the pumba pod on app node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:76\ntime:2019-10-22T09:32:51.907859 (delta: 0.059927)         elapsed: 16.274643  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod -l app=pumba -o wide -n default | grep minikube | awk '{print $1}'\", \"delta\": \"0:00:00.457465\", \"end\": \"2019-10-22 09:32:52.463953\", \"rc\": 0, \"start\": \"2019-10-22 09:32:52.006488\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"pumba-m9fhv\", \"stdout_lines\": [\"pumba-m9fhv\"]}\n``` \n\n## TASK [Record restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:85\ntime:2019-10-22T09:32:52.497435 (delta: 0.589554)         elapsed: 16.864219  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl get pod cass-demo-dc1-rack1-0 -n default -o=jsonpath='{.status.containerStatuses[?(@.name==\\\"cassandra\\\")].restartCount}'\", \"delta\": \"0:00:00.445335\", \"end\": \"2019-10-22 09:32:53.043548\", \"rc\": 0, \"start\": \"2019-10-22 09:32:52.598213\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"5\", \"stdout_lines\": [\"5\"]}\n``` \n\n## TASK [Force kill the application pod using pumba] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:93\ntime:2019-10-22T09:32:53.077400 (delta: 0.579931)         elapsed: 17.444184  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl exec pumba-m9fhv -n default -- pumba kill --signal SIGKILL re2:k8s_cassandra_;\", \"delta\": \"0:00:02.174077\", \"end\": \"2019-10-22 09:32:55.351290\", \"rc\": 0, \"start\": \"2019-10-22 09:32:53.177213\", \"stderr\": \"time=\\\"2019-10-22T09:32:53Z\\\" level=info msg=\\\"Kill containers\\\" \\ntime=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-1_default_af292200-2d06-4f19-9970-e64d00ed8302_5 (adf6e7b0f6a8c4e23be92ac5f291e8809bd47205716f55252db121313be4dd00) with signal SIGKILL\\\" \\ntime=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-0_default_3fcd5226-3229-4deb-9930-279e6eec50cc_5 (f84f21e935ce22b26c8c4053354726b34e515e94f64b27e3e0564c929e1472f4) with signal SIGKILL\\\" \", \"stderr_lines\": [\"time=\\\"2019-10-22T09:32:53Z\\\" level=info msg=\\\"Kill containers\\\" \", \"time=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-1_default_af292200-2d06-4f19-9970-e64d00ed8302_5 (adf6e7b0f6a8c4e23be92ac5f291e8809bd47205716f55252db121313be4dd00) with signal SIGKILL\\\" \", \"time=\\\"2019-10-22T09:32:55Z\\\" level=info msg=\\\"Killing /k8s_cassandra_cass-demo-dc1-rack1-0_default_3fcd5226-3229-4deb-9930-279e6eec50cc_5 (f84f21e935ce22b26c8c4053354726b34e515e94f64b27e3e0564c929e1472f4) with signal SIGKILL\\\" \"], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Verify restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:102\ntime:2019-10-22T09:32:55.389173 (delta: 2.311746)         elapsed: 19.755957  \nFAILED - RETRYING: Verify restartCount (30 retries left).\nchanged: [127.0.0.1] => {\"attempts\": 2, \"changed\": true, \"cmd\": \"kubectl get pod cass-demo-dc1-rack1-0 -n default -o=jsonpath='{.status.containerStatuses[?(@.name==\\\"cassandra\\\")].restartCount}'\", \"delta\": \"0:00:00.471000\", \"end\": \"2019-10-22 09:32:58.525225\", \"rc\": 0, \"start\": \"2019-10-22 09:32:58.054225\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"6\", \"stdout_lines\": [\"6\"]}\n``` \n\n## TASK [Check if pumba is indeed running] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:117\ntime:2019-10-22T09:32:58.565366 (delta: 3.176158)         elapsed: 22.93215  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Delete the pumba daemonset] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:132\ntime:2019-10-22T09:32:58.617708 (delta: 0.052315)         elapsed: 22.984492  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Confirm that the pumba ds is deleted successfully] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:139\ntime:2019-10-22T09:32:58.658968 (delta: 0.041197)         elapsed: 23.025752  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Checkpoint] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:127\ntime:2019-10-22T09:32:58.702607 (delta: 0.043593)         elapsed: 23.069391  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Verify AUT liveness post fault-injection] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:134\ntime:2019-10-22T09:32:58.746531 (delta: 0.043879)         elapsed: 23.113315  \nincluded: /utils/k8s/check_deployment_status.yml for 127.0.0.1\n``` \n\n## TASK [Check the pod status] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:8\ntime:2019-10-22T09:32:58.808217 (delta: 0.061654)         elapsed: 23.175001  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [obtain the number of replicas.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:22\ntime:2019-10-22T09:32:58.850771 (delta: 0.042514)         elapsed: 23.217555  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:spec.replicas\", \"delta\": \"0:00:00.487258\", \"end\": \"2019-10-22 09:32:59.454084\", \"rc\": 0, \"start\": \"2019-10-22 09:32:58.966826\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Obtain the ready replica count and compare with the replica count.] \n``` \ntask path: /utils/k8s/check_deployment_status.yml:29\ntime:2019-10-22T09:32:59.502144 (delta: 0.651351)         elapsed: 23.868928  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get statefulset -n default -l statefulset.kubernetes.io/pod-name=cass-demo-dc1-rack1-0 -o custom-columns=:..readyReplicas\", \"delta\": \"0:00:00.460006\", \"end\": \"2019-10-22 09:33:00.079589\", \"rc\": 0, \"start\": \"2019-10-22 09:32:59.619583\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\n``` \n\n## TASK [Checking status of liveness pod] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:139\ntime:2019-10-22T09:33:00.131823 (delta: 0.629637)         elapsed: 24.498607  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [set_fact] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:148\ntime:2019-10-22T09:33:00.169972 (delta: 0.038111)         elapsed: 24.536756  \nok: [127.0.0.1] => {\"ansible_facts\": {\"flag\": \"Pass\"}, \"changed\": false}\n``` \n\n## TASK [Generate the litmus result CR to reflect EOT (End of Test)] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:159\ntime:2019-10-22T09:33:00.230381 (delta: 0.060385)         elapsed: 24.597165  \nchanged: [127.0.0.1] => {\"changed\": true, \"checksum\": \"0ce715eedb8ca906ea535c15dc4cf27e5c351360\", \"dest\": \"./litmus-result.yaml\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"e9d551b88b01b393b3e36a1afeb12822\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 414, \"src\": \"/root/.ansible/tmp/ansible-tmp-1571736780.27-79185624627260/source\", \"state\": \"file\", \"uid\": 0}\n``` \n\n## TASK [Apply the litmus result CR] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:170\ntime:2019-10-22T09:33:01.259316 (delta: 1.028891)         elapsed: 25.6261  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl apply -f litmus-result.yaml\", \"delta\": \"0:00:00.680528\", \"end\": \"2019-10-22 09:33:02.041191\", \"failed_when_result\": false, \"rc\": 0, \"start\": \"2019-10-22 09:33:01.360663\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"litmusresult.litmus.io/app-pod-failure configured\", \"stdout_lines\": [\"litmusresult.litmus.io/app-pod-failure configured\"]}\n``` \n\n## TASK [include_tasks] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:177\ntime:2019-10-22T09:33:02.082162 (delta: 0.822823)         elapsed: 26.448946  \nincluded: /chaoslib/pumba/pod_failure_by_sigkill.yaml for 127.0.0.1\n``` \n\n## TASK [Setup pumba chaos infrastructure] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:4\ntime:2019-10-22T09:33:02.167201 (delta: 0.084983)         elapsed: 26.533985  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Confirm that the pumba ds is running on all nodes] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:13\ntime:2019-10-22T09:33:02.210265 (delta: 0.043041)         elapsed: 26.577049  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Select the app pod] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:27\ntime:2019-10-22T09:33:02.246121 (delta: 0.035817)         elapsed: 26.612905  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:36\ntime:2019-10-22T09:33:02.279515 (delta: 0.033368)         elapsed: 26.646299  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record application pod name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:43\ntime:2019-10-22T09:33:02.313912 (delta: 0.034359)         elapsed: 26.680696  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Identify the application node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:49\ntime:2019-10-22T09:33:02.348276 (delta: 0.034334)         elapsed: 26.71506  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the application node name] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:57\ntime:2019-10-22T09:33:02.382690 (delta: 0.034383)         elapsed: 26.749474  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the application container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:63\ntime:2019-10-22T09:33:02.423818 (delta: 0.041072)         elapsed: 26.790602  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the app_container] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:70\ntime:2019-10-22T09:33:02.460732 (delta: 0.036856)         elapsed: 26.827516  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record the pumba pod on app node] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:76\ntime:2019-10-22T09:33:02.524203 (delta: 0.06345)         elapsed: 26.890987  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:85\ntime:2019-10-22T09:33:02.581366 (delta: 0.057111)         elapsed: 26.94815  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Force kill the application pod using pumba] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:93\ntime:2019-10-22T09:33:02.624084 (delta: 0.042667)         elapsed: 26.990868  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Verify restartCount] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:102\ntime:2019-10-22T09:33:02.656630 (delta: 0.032513)         elapsed: 27.023414  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Check if pumba is indeed running] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:117\ntime:2019-10-22T09:33:02.694621 (delta: 0.037969)         elapsed: 27.061405  \nchanged: [127.0.0.1] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get pod -l app=pumba --no-headers -o custom-columns=:status.phase -n default | sort | uniq\", \"delta\": \"0:00:00.474286\", \"end\": \"2019-10-22 09:33:03.279996\", \"rc\": 0, \"start\": \"2019-10-22 09:33:02.805710\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"Running\", \"stdout_lines\": [\"Running\"]}\n``` \n\n## TASK [Delete the pumba daemonset] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:132\ntime:2019-10-22T09:33:03.322117 (delta: 0.627443)         elapsed: 27.688901  \nchanged: [127.0.0.1] => {\"changed\": true, \"cmd\": \"kubectl delete -f /chaoslib/pumba/pumba_kube.yaml -n default\", \"delta\": \"0:00:00.497277\", \"end\": \"2019-10-22 09:33:03.942872\", \"rc\": 0, \"start\": \"2019-10-22 09:33:03.445595\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"daemonset.extensions \\\"pumba\\\" deleted\", \"stdout_lines\": [\"daemonset.extensions \\\"pumba\\\" deleted\"]}\n``` \n\n## TASK [Confirm that the pumba ds is deleted successfully] \n``` \ntask path: /chaoslib/pumba/pod_failure_by_sigkill.yaml:139\ntime:2019-10-22T09:33:03.978190 (delta: 0.656028)         elapsed: 28.344974  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Cleanup] \n``` \ntask path: /experiments/chaos/app-pod-failure/test.yml:186\ntime:2019-10-22T09:33:04.018832 (delta: 0.040603)         elapsed: 28.385616  \nskipping: [127.0.0.1] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\nMETA: ran handlers\nMETA: ran handlers\nPLAY RECAP \n7.0.0.1\u001b[0m                  : \u001b[0;32mok=29  \u001b[0m \u001b[0;33mchanged=19  \u001b[0m unreachable=0    failed=0   \ntime:2019-10-22T09:33:04.045610 (delta: 0.026746)         elapsed: 28.412394  \namber: case app-pod-failure is going to finish...\namber: result would be available in CRD 'litmusresult' form. Use 'kubectl get lr' for details.\n``` \n"},{"title":"CommitID[ cfe2ff09f9]2019-10-25T14:31:50","tag":["pod-delete"],"time":"2019-10-25 14:31:50","url":"/post/2019-10-25T14:31:50","thumb":"/contents/2019-10-25T14:31:50/thumb.jpg","content":"=== \n标题： CommitID[ cfe2ff09f9]2019-10-25T14:31:50\n标签： pod-delete\n\n=== \n\n# Summary report \n| Task status | number |\n| ------------ | ------------ |\n|      ok |      27\n|      change |      17\n|      unreachable |      0\n|      failed |      0\n# Info report \n ``` \nUsing /etc/ansible/ansible.cfg as config file\nPLAY [localhost] \n``` \n\n## TASK [Gathering Facts] \n``` \nok: [localhost]\n``` \n\n## TASK [Test KinD] \n``` \nchanged: [localhost] => {\"changed\": true, \"cmd\": \"kubectl get pods --all-namespaces\\n\", \"delta\": \"0:00:03.740048\", \"end\": \"2019-10-25 14:30:41.698691\", \"rc\": 0, \"start\": \"2019-10-25 14:30:37.958643\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"NAMESPACE     NAME                                         READY   STATUS    RESTARTS   AGE\\nkube-system   coredns-5c98db65d4-2zh8z                     1/1     Running   0          57s\\nkube-system   coredns-5c98db65d4-zb5b2                     1/1     Running   0          57s\\nkube-system   kindnet-z5pdm                                1/1     Running   1          57s\\nkube-system   kube-apiserver-kind-control-plane            1/1     Running   0          20s\\nkube-system   kube-controller-manager-kind-control-plane   1/1     Running   0          17s\\nkube-system   kube-proxy-qt8sf                             1/1     Running   0          57s\\nkube-system   kube-scheduler-kind-control-plane            1/1     Running   0          19s\", \"stdout_lines\": [\"NAMESPACE     NAME                                         READY   STATUS    RESTARTS   AGE\", \"kube-system   coredns-5c98db65d4-2zh8z                     1/1     Running   0          57s\", \"kube-system   coredns-5c98db65d4-zb5b2                     1/1     Running   0          57s\", \"kube-system   kindnet-z5pdm                                1/1     Running   1          57s\", \"kube-system   kube-apiserver-kind-control-plane            1/1     Running   0          20s\", \"kube-system   kube-controller-manager-kind-control-plane   1/1     Running   0          17s\", \"kube-system   kube-proxy-qt8sf                             1/1     Running   0          57s\", \"kube-system   kube-scheduler-kind-control-plane            1/1     Running   0          19s\"]}\n``` \n\n## TASK [Test] \n``` \nchanged: [localhost] => {\"changed\": true, \"cmd\": \"echo \\\"hello action!\\\"\\n\", \"delta\": \"0:00:00.005395\", \"end\": \"2019-10-25 14:30:41.876216\", \"rc\": 0, \"start\": \"2019-10-25 14:30:41.870821\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"hello action!\", \"stdout_lines\": [\"hello action!\"]}\n``` \n\n## TASK [Create new ns] \n``` \nchanged: [localhost] => {\"changed\": true, \"cmd\": \"kubectl create ns mysql-operator\", \"delta\": \"0:00:00.087690\", \"end\": \"2019-10-25 14:30:42.138119\", \"rc\": 0, \"start\": \"2019-10-25 14:30:42.050429\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"namespace/mysql-operator created\", \"stdout_lines\": [\"namespace/mysql-operator created\"]}\n``` \n\n## TASK [Deploy the app] \n``` \nincluded: /home/runner/work/githubAction/githubAction/Kube-Test/funclib/helm_deployer.yaml for localhost\n``` \n\n## TASK [Get github workspace] \n``` \nok: [localhost] => {\"ansible_facts\": {\"github_workspace\": \"/home/runner/work/githubAction/githubAction\"}, \"changed\": false}\n``` \n\n## TASK [Get the chart name] \n``` \nchanged: [localhost] => {\"changed\": true, \"cmd\": \"echo $(basename charts/kubedb )\", \"delta\": \"0:00:00.008627\", \"end\": \"2019-10-25 14:30:42.491659\", \"rc\": 0, \"start\": \"2019-10-25 14:30:42.483032\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"kubedb\", \"stdout_lines\": [\"kubedb\"]}\n``` \n\n## TASK [Install tiller] \n``` \nchanged: [localhost] => {\"changed\": true, \"cmd\": \"helm init\", \"delta\": \"0:00:04.349508\", \"end\": \"2019-10-25 14:30:47.020567\", \"rc\": 0, \"start\": \"2019-10-25 14:30:42.671059\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"Creating /home/runner/.helm \\nCreating /home/runner/.helm/repository \\nCreating /home/runner/.helm/repository/cache \\nCreating /home/runner/.helm/repository/local \\nCreating /home/runner/.helm/plugins \\nCreating /home/runner/.helm/starters \\nCreating /home/runner/.helm/cache/archive \\nCreating /home/runner/.helm/repository/repositories.yaml \\nAdding stable repo with URL: https://kubernetes-charts.storage.googleapis.com \\nAdding local repo with URL: http://127.0.0.1:8879/charts \\n$HELM_HOME has been configured at /home/runner/.helm.\\n\\nTiller (the Helm server-side component) has been installed into your Kubernetes Cluster.\\n\\nPlease note: by default, Tiller is deployed with an insecure 'allow unauthenticated users' policy.\\nTo prevent this, run `helm init` with the --tiller-tls-verify flag.\\nFor more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation\", \"stdout_lines\": [\"Creating /home/runner/.helm \", \"Creating /home/runner/.helm/repository \", \"Creating /home/runner/.helm/repository/cache \", \"Creating /home/runner/.helm/repository/local \", \"Creating /home/runner/.helm/plugins \", \"Creating /home/runner/.helm/starters \", \"Creating /home/runner/.helm/cache/archive \", \"Creating /home/runner/.helm/repository/repositories.yaml \", \"Adding stable repo with URL: https://kubernetes-charts.storage.googleapis.com \", \"Adding local repo with URL: http://127.0.0.1:8879/charts \", \"$HELM_HOME has been configured at /home/runner/.helm.\", \"\", \"Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster.\", \"\", \"Please note: by default, Tiller is deployed with an insecure 'allow unauthenticated users' policy.\", \"To prevent this, run `helm init` with the --tiller-tls-verify flag.\", \"For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation\"]}\n``` \n\n## TASK [Wait until tiller is installed] \n``` \nFAILED - RETRYING: Wait until tiller is installed (120 retries left).\nFAILED - RETRYING: Wait until tiller is installed (119 retries left).\nFAILED - RETRYING: Wait until tiller is installed (118 retries left).\nFAILED - RETRYING: Wait until tiller is installed (117 retries left).\nchanged: [localhost] => {\"attempts\": 5, \"changed\": true, \"cmd\": \"helm version\", \"delta\": \"0:00:00.183862\", \"end\": \"2019-10-25 14:31:08.439667\", \"rc\": 0, \"start\": \"2019-10-25 14:31:08.255805\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"Client: &version.Version{SemVer:\\\"v2.14.3\\\", GitCommit:\\\"0e7f3b6637f7af8fcfddb3d2941fcc7cbebb0085\\\", GitTreeState:\\\"clean\\\"}\\nServer: &version.Version{SemVer:\\\"v2.14.3\\\", GitCommit:\\\"0e7f3b6637f7af8fcfddb3d2941fcc7cbebb0085\\\", GitTreeState:\\\"clean\\\"}\", \"stdout_lines\": [\"Client: &version.Version{SemVer:\\\"v2.14.3\\\", GitCommit:\\\"0e7f3b6637f7af8fcfddb3d2941fcc7cbebb0085\\\", GitTreeState:\\\"clean\\\"}\", \"Server: &version.Version{SemVer:\\\"v2.14.3\\\", GitCommit:\\\"0e7f3b6637f7af8fcfddb3d2941fcc7cbebb0085\\\", GitTreeState:\\\"clean\\\"}\"]}\n``` \n\n## TASK [Wait until tiller is installed] \n``` \nchanged: [localhost] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get pod -n kube-system | grep tiller-deploy\", \"delta\": \"0:00:00.150656\", \"end\": \"2019-10-25 14:31:08.779941\", \"rc\": 0, \"start\": \"2019-10-25 14:31:08.629285\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"tiller-deploy-75f6c87b87-cl5gm               1/1     Running   0          22s\", \"stdout_lines\": [\"tiller-deploy-75f6c87b87-cl5gm               1/1     Running   0          22s\"]}\n``` \n\n## TASK [Authorization the tiller to deploy application] \n``` \nchanged: [localhost] => {\"changed\": true, \"cmd\": \"kubectl create clusterrolebinding permissive-binding  --clusterrole=cluster-admin  --user=admin  --user=kubelet  --group=system:serviceaccounts\\n\", \"delta\": \"0:00:00.139167\", \"end\": \"2019-10-25 14:31:09.099674\", \"rc\": 0, \"start\": \"2019-10-25 14:31:08.960507\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"clusterrolebinding.rbac.authorization.k8s.io/permissive-binding created\", \"stdout_lines\": [\"clusterrolebinding.rbac.authorization.k8s.io/permissive-binding created\"]}\n``` \n\n## TASK [Deploy the application to the cluster.] \n``` \nchanged: [localhost] => {\"changed\": true, \"cmd\": \"helm install /home/runner/work/githubAction/githubAction/charts/kubedb --name kubedb\", \"delta\": \"0:00:19.880568\", \"end\": \"2019-10-25 14:31:29.162977\", \"rc\": 0, \"start\": \"2019-10-25 14:31:09.282409\", \"stderr\": \"E1025 14:31:28.981058   33244 portforward.go:385] error copying from local connection to remote stream: read tcp4 127.0.0.1:43039->127.0.0.1:44694: read: connection reset by peer\", \"stderr_lines\": [\"E1025 14:31:28.981058   33244 portforward.go:385] error copying from local connection to remote stream: read tcp4 127.0.0.1:43039->127.0.0.1:44694: read: connection reset by peer\"], \"stdout\": \"NAME:   kubedb\\nLAST DEPLOYED: Fri Oct 25 14:31:09 2019\\nNAMESPACE: default\\nSTATUS: DEPLOYED\\n\\nRESOURCES:\\n==> v1/ClusterRole\\nNAME    AGE\\nkubedb  19s\\n\\n==> v1/ClusterRoleBinding\\nNAME                             AGE\\nkubedb                           19s\\nkubedb-apiserver-auth-delegator  19s\\n\\n==> v1/Deployment\\nNAME    READY  UP-TO-DATE  AVAILABLE  AGE\\nkubedb  0/1    1           0          19s\\n\\n==> v1/Pod(related)\\nNAME                     READY  STATUS   RESTARTS  AGE\\nkubedb-5b4fc7464f-qj4st  0/1    Running  0         19s\\n\\n==> v1/RoleBinding\\nNAME                                                     AGE\\nkubedb-apiserver-extension-server-authentication-reader  19s\\n\\n==> v1/Secret\\nNAME                   TYPE    DATA  AGE\\nkubedb-apiserver-cert  Opaque  2     19s\\n\\n==> v1/Service\\nNAME    TYPE       CLUSTER-IP      EXTERNAL-IP  PORT(S)  AGE\\nkubedb  ClusterIP  10.107.136.233  <none>       443/TCP  19s\\n\\n==> v1/ServiceAccount\\nNAME    SECRETS  AGE\\nkubedb  1        19s\\n\\n==> v1beta1/APIService\\nNAME                            AGE\\nv1alpha1.mutators.kubedb.com    19s\\nv1alpha1.validators.kubedb.com  19s\\n\\n==> v1beta1/PodSecurityPolicy\\nNAME    PRIV  CAPS                   SELINUX   RUNASUSER  FSGROUP   SUPGROUP  READONLYROOTFS  VOLUMES\\nkubedb  true  IPC_LOCK,SYS_RESOURCE  RunAsAny  RunAsAny   RunAsAny  RunAsAny  false           \\n\\n\\nNOTES:\\nTo verify that KubeDB has started, run:\\n\\n  kubectl --namespace=default get deployments -l \\\"release=kubedb, app=kubedb\\\"\\n\\nNow install/upgrade appscode/kubedb-catalog chart.\\n\\nTo install, run:\\n\\n  helm install appscode/kubedb-catalog --name kubedb-catalog --version v0.13.0-rc.0 --namespace default\\n\\nTo upgrade, run:\\n\\n  helm upgrade kubedb-catalog appscode/kubedb-catalog --version v0.13.0-rc.0 --namespace default\", \"stdout_lines\": [\"NAME:   kubedb\", \"LAST DEPLOYED: Fri Oct 25 14:31:09 2019\", \"NAMESPACE: default\", \"STATUS: DEPLOYED\", \"\", \"RESOURCES:\", \"==> v1/ClusterRole\", \"NAME    AGE\", \"kubedb  19s\", \"\", \"==> v1/ClusterRoleBinding\", \"NAME                             AGE\", \"kubedb                           19s\", \"kubedb-apiserver-auth-delegator  19s\", \"\", \"==> v1/Deployment\", \"NAME    READY  UP-TO-DATE  AVAILABLE  AGE\", \"kubedb  0/1    1           0          19s\", \"\", \"==> v1/Pod(related)\", \"NAME                     READY  STATUS   RESTARTS  AGE\", \"kubedb-5b4fc7464f-qj4st  0/1    Running  0         19s\", \"\", \"==> v1/RoleBinding\", \"NAME                                                     AGE\", \"kubedb-apiserver-extension-server-authentication-reader  19s\", \"\", \"==> v1/Secret\", \"NAME                   TYPE    DATA  AGE\", \"kubedb-apiserver-cert  Opaque  2     19s\", \"\", \"==> v1/Service\", \"NAME    TYPE       CLUSTER-IP      EXTERNAL-IP  PORT(S)  AGE\", \"kubedb  ClusterIP  10.107.136.233  <none>       443/TCP  19s\", \"\", \"==> v1/ServiceAccount\", \"NAME    SECRETS  AGE\", \"kubedb  1        19s\", \"\", \"==> v1beta1/APIService\", \"NAME                            AGE\", \"v1alpha1.mutators.kubedb.com    19s\", \"v1alpha1.validators.kubedb.com  19s\", \"\", \"==> v1beta1/PodSecurityPolicy\", \"NAME    PRIV  CAPS                   SELINUX   RUNASUSER  FSGROUP   SUPGROUP  READONLYROOTFS  VOLUMES\", \"kubedb  true  IPC_LOCK,SYS_RESOURCE  RunAsAny  RunAsAny   RunAsAny  RunAsAny  false           \", \"\", \"\", \"NOTES:\", \"To verify that KubeDB has started, run:\", \"\", \"  kubectl --namespace=default get deployments -l \\\"release=kubedb, app=kubedb\\\"\", \"\", \"Now install/upgrade appscode/kubedb-catalog chart.\", \"\", \"To install, run:\", \"\", \"  helm install appscode/kubedb-catalog --name kubedb-catalog --version v0.13.0-rc.0 --namespace default\", \"\", \"To upgrade, run:\", \"\", \"  helm upgrade kubedb-catalog appscode/kubedb-catalog --version v0.13.0-rc.0 --namespace default\"]}\n``` \n\n## TASK [Check if the application has been deployed] \n``` \nchanged: [localhost] => {\"changed\": true, \"cmd\": \"helm list\", \"delta\": \"0:00:00.119527\", \"end\": \"2019-10-25 14:31:29.495570\", \"rc\": 0, \"start\": \"2019-10-25 14:31:29.376043\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"NAME  \\tREVISION\\tUPDATED                 \\tSTATUS  \\tCHART              \\tAPP VERSION \\tNAMESPACE\\nkubedb\\t1       \\tFri Oct 25 14:31:09 2019\\tDEPLOYED\\tkubedb-v0.13.0-rc.0\\tv0.13.0-rc.0\\tdefault  \", \"stdout_lines\": [\"NAME  \\tREVISION\\tUPDATED                 \\tSTATUS  \\tCHART              \\tAPP VERSION \\tNAMESPACE\", \"kubedb\\t1       \\tFri Oct 25 14:31:09 2019\\tDEPLOYED\\tkubedb-v0.13.0-rc.0\\tv0.13.0-rc.0\\tdefault  \"]}\n``` \n\n## TASK [Apply the CRD into cluster] \n``` \nchanged: [localhost] => {\"changed\": true, \"cmd\": \"kubectl create -f ../Kube-Test/manifest/crds.yaml\\nkubectl create -f ../Kube-Test/manifest/rbac.yaml\\n\", \"delta\": \"0:00:00.730510\", \"end\": \"2019-10-25 14:31:30.410157\", \"rc\": 0, \"start\": \"2019-10-25 14:31:29.679647\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"customresourcedefinition.apiextensions.k8s.io/litmusresults.litmus.io created\\ncustomresourcedefinition.apiextensions.k8s.io/chaosresults.litmuschaos.io created\\nnamespace/litmus created\\nserviceaccount/litmus created\\nclusterrole.rbac.authorization.k8s.io/litmus created\\nclusterrolebinding.rbac.authorization.k8s.io/litmus created\", \"stdout_lines\": [\"customresourcedefinition.apiextensions.k8s.io/litmusresults.litmus.io created\", \"customresourcedefinition.apiextensions.k8s.io/chaosresults.litmuschaos.io created\", \"namespace/litmus created\", \"serviceaccount/litmus created\", \"clusterrole.rbac.authorization.k8s.io/litmus created\", \"clusterrolebinding.rbac.authorization.k8s.io/litmus created\"]}\n``` \n\n## TASK [Authorization the tiller to deploy application] \n``` \nskipping: [localhost] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Add chart repository.] \n``` \nskipping: [localhost] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Deploy the application from chart repository.] \n``` \nskipping: [localhost] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Check if the application has been deployed] \n``` \nskipping: [localhost] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Apply the CRD into cluster] \n``` \nskipping: [localhost] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Delete the deplyed application] \n``` \nskipping: [localhost] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Test Pod Faliure] \n``` \nincluded: /home/runner/work/githubAction/githubAction/Kube-Test/experiments/pod-delete.yaml for localhost\n``` \n\n## TASK [Setup] \n``` \nskipping: [localhost] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Record test instance/run ID] \n``` \nskipping: [localhost] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Construct testname appended with runID] \n``` \nskipping: [localhost] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Generate the litmus result CR to reflect SOT (Start of Test)] \n``` \nchanged: [localhost] => {\"changed\": true, \"checksum\": \"42f674ba56a4b4cd9b06fef317fd1a6c3d4308e8\", \"dest\": \"./pod-delete-litmus-result.yaml\", \"gid\": 115, \"group\": \"docker\", \"md5sum\": \"0ccb5e6064ec023f4bc627f0350194cf\", \"mode\": \"0644\", \"owner\": \"runner\", \"size\": 410, \"src\": \"/home/runner/.ansible/tmp/ansible-tmp-1572013891.08-96194978858273/source\", \"state\": \"file\", \"uid\": 1001}\n``` \n\n## TASK [Display the app information passed via the test job] \n``` \nok: [localhost] => {\n    \"msg\": [\n        \"The application info is as follows:\", \n        \"Namespace    : default\", \n        \"Label        : app=kubedb\"\n    ]\n}\n``` \n\n## TASK [Verify that the AUT (Application Under Test) is running] \n``` \nincluded: /home/runner/work/githubAction/githubAction/Kube-Test/utils/k8s/status_app_pod.yml for localhost\n``` \n\n## TASK [Get the container status of application.] \n``` \nchanged: [localhost] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get pod -n default -l app=\\\"kubedb\\\" -o custom-columns=:..containerStatuses --no-headers | grep -w \\\"map\\\\\\\\[running\\\"\\n\", \"delta\": \"0:00:00.156691\", \"end\": \"2019-10-25 14:31:32.180969\", \"rc\": 0, \"start\": \"2019-10-25 14:31:32.024278\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"[map[containerID:containerd://28de38314bd0368457561e63b0d70af7d11db167395ff4e920a97e39a41c4cb4 image:docker.io/kubedb/operator:v0.13.0-rc.0 imageID:docker.io/kubedb/operator@sha256:0833d5f841831433b87a656b0c8295b2c1e6b551c372a3d7db63b26fe15730bd lastState:map[] name:operator ready:false restartCount:0 state:map[running:map[startedAt:2019-10-25T14:31:18Z]]]]\", \"stdout_lines\": [\"[map[containerID:containerd://28de38314bd0368457561e63b0d70af7d11db167395ff4e920a97e39a41c4cb4 image:docker.io/kubedb/operator:v0.13.0-rc.0 imageID:docker.io/kubedb/operator@sha256:0833d5f841831433b87a656b0c8295b2c1e6b551c372a3d7db63b26fe15730bd lastState:map[] name:operator ready:false restartCount:0 state:map[running:map[startedAt:2019-10-25T14:31:18Z]]]]\"]}\n``` \n\n## TASK [Checking {{ application_name }} pod is in running state] \n``` \nchanged: [localhost] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get pods -n default -o jsonpath='{.items[?(@.metadata.labels.app==\\\"kubedb\\\")].status.phase}'\", \"delta\": \"0:00:00.127316\", \"end\": \"2019-10-25 14:31:32.498033\", \"rc\": 0, \"start\": \"2019-10-25 14:31:32.370717\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"Running\", \"stdout_lines\": [\"Running\"]}\n``` \n\n## TASK [include_tasks] \n``` \nincluded: /home/runner/work/githubAction/githubAction/Kube-Test/chaoslib/litmus/app_pod_random_delete.yaml for localhost\n``` \n\n## TASK [Derive chaos iterations] \n``` \nok: [localhost] => {\"ansible_facts\": {\"chaos_iterations\": \"3\"}, \"changed\": false}\n``` \n\n## TASK [Set min chaos count to 1 if interval > duration] \n``` \nskipping: [localhost] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Kill application pods randomly for the specified duration] \n``` \nchanged: [localhost] => (item=1) => {\"ansible_loop_var\": \"item\", \"changed\": true, \"cmd\": \"kubectl get pods -l app=kubedb -n default --no-headers -o custom-columns=:metadata.name | shuf -n 1 | xargs kubectl delete pod -n default --force --grace-period=0 --wait=false\\nsleep 5\\n\", \"delta\": \"0:00:05.252241\", \"end\": \"2019-10-25 14:31:38.154681\", \"item\": \"1\", \"rc\": 0, \"start\": \"2019-10-25 14:31:32.902440\", \"stderr\": \"warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\", \"stderr_lines\": [\"warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\"], \"stdout\": \"pod \\\"kubedb-5b4fc7464f-qj4st\\\" force deleted\", \"stdout_lines\": [\"pod \\\"kubedb-5b4fc7464f-qj4st\\\" force deleted\"]}\nchanged: [localhost] => (item=2) => {\"ansible_loop_var\": \"item\", \"changed\": true, \"cmd\": \"kubectl get pods -l app=kubedb -n default --no-headers -o custom-columns=:metadata.name | shuf -n 1 | xargs kubectl delete pod -n default --force --grace-period=0 --wait=false\\nsleep 5\\n\", \"delta\": \"0:00:05.292054\", \"end\": \"2019-10-25 14:31:43.583268\", \"item\": \"2\", \"rc\": 0, \"start\": \"2019-10-25 14:31:38.291214\", \"stderr\": \"warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\", \"stderr_lines\": [\"warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\"], \"stdout\": \"pod \\\"kubedb-5b4fc7464f-5mbhr\\\" force deleted\", \"stdout_lines\": [\"pod \\\"kubedb-5b4fc7464f-5mbhr\\\" force deleted\"]}\nchanged: [localhost] => (item=3) => {\"ansible_loop_var\": \"item\", \"changed\": true, \"cmd\": \"kubectl get pods -l app=kubedb -n default --no-headers -o custom-columns=:metadata.name | shuf -n 1 | xargs kubectl delete pod -n default --force --grace-period=0 --wait=false\\nsleep 5\\n\", \"delta\": \"0:00:05.262403\", \"end\": \"2019-10-25 14:31:48.998154\", \"item\": \"3\", \"rc\": 0, \"start\": \"2019-10-25 14:31:43.735751\", \"stderr\": \"warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\", \"stderr_lines\": [\"warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\"], \"stdout\": \"pod \\\"kubedb-5b4fc7464f-kh9wr\\\" force deleted\", \"stdout_lines\": [\"pod \\\"kubedb-5b4fc7464f-kh9wr\\\" force deleted\"]}\n``` \n\n## TASK [Kill application pods randomly for the specified duration] \n``` \nskipping: [localhost] => (item=1)  => {\"ansible_loop_var\": \"item\", \"changed\": false, \"item\": \"1\", \"skip_reason\": \"Conditional result was False\"}\nskipping: [localhost] => (item=2)  => {\"ansible_loop_var\": \"item\", \"changed\": false, \"item\": \"2\", \"skip_reason\": \"Conditional result was False\"}\nskipping: [localhost] => (item=3)  => {\"ansible_loop_var\": \"item\", \"changed\": false, \"item\": \"3\", \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Checkpoint] \n``` \nskipping: [localhost] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Verify AUT liveness post fault-injection] \n``` \nincluded: /home/runner/work/githubAction/githubAction/Kube-Test/utils/k8s/check_deployment_status.yml for localhost\n``` \n\n## TASK [Check the pod status] \n``` \nchanged: [localhost] => {\"attempts\": 1, \"changed\": true, \"cmd\": \"kubectl get pods -n default -l app=kubedb --no-headers -o custom-columns=:status.phase\\n\", \"delta\": \"0:00:00.088265\", \"end\": \"2019-10-25 14:31:49.490437\", \"rc\": 0, \"start\": \"2019-10-25 14:31:49.402172\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"Running\", \"stdout_lines\": [\"Running\"]}\n``` \n\n## TASK [obtain the number of replicas.] \n``` \nskipping: [localhost] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [Obtain the ready replica count and compare with the replica count.] \n``` \nskipping: [localhost] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\n``` \n\n## TASK [set_fact] \n``` \nok: [localhost] => {\"ansible_facts\": {\"flag\": \"pass\"}, \"changed\": false}\n``` \n\n## TASK [Generate the litmus result CR to reflect EOT (End of Test)] \n``` \nchanged: [localhost] => {\"changed\": true, \"checksum\": \"7df8c5fb6c900e2a8029d5f8d2c56f9dbe4f4ceb\", \"dest\": \"./pod-delete-litmus-result.yaml\", \"gid\": 115, \"group\": \"docker\", \"md5sum\": \"c462a04fd9d577f9c5b979b9e051f6ce\", \"mode\": \"0644\", \"owner\": \"runner\", \"size\": 408, \"src\": \"/home/runner/.ansible/tmp/ansible-tmp-1572013909.71-44695785357842/source\", \"state\": \"file\", \"uid\": 1001}\n``` \n\n## TASK [Cleanup] \n``` \nskipping: [localhost] => {\"changed\": false, \"skip_reason\": \"Conditional result was False\"}\nPLAY RECAP \nlocalhost                  : ok=27   changed=17   unreachable=0    failed=0    skipped=15   rescued=0    ignored=0 \ncfe2ff09f921df83eb076d8e536a0ed3fe3658\n``` \n"}]